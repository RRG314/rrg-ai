{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdCXhezyr5pVz4oSVFpNP9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RRG314/RRG-AI/blob/steven%2Fplugin-system/rdt_lm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "UQUzJ17Q9j6c",
        "outputId": "def4da96-9046-419d-bb31-3ce968dc496f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 116)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m116\u001b[0m\n\u001b[0;31m    def train_rdt(self, corpus, epochs=10, lr=1e-3):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "RDT LANGUAGE MODEL + Topological Adam Optimizer Integration\n",
        "Author: Steven Reid\n",
        "License: Apache 2.0\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from topological_adam import TopologicalAdam   # â† installed package\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Using: {device}\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# RDT MATH\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    \"\"\"Doubly-logarithmic depth calculation\"\"\"\n",
        "    if n < 2:\n",
        "        return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d:\n",
        "            break\n",
        "        x //= d\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "\n",
        "def generate_corpus():\n",
        "    patterns = [\n",
        "        \"the man walked to the house\",\n",
        "        \"the woman went to the market\",\n",
        "        \"the child ran to the river\",\n",
        "        \"he was happy and she was sad\",\n",
        "        \"they found the truth and left quickly\",\n",
        "        \"in the morning he woke up early\",\n",
        "        \"at night she went to sleep\",\n",
        "        \"the old king ruled the land wisely\",\n",
        "        \"the young prince sought great adventure\",\n",
        "        \"once there was a wise teacher\",\n",
        "        \"the forest was dark and very quiet\",\n",
        "        \"he said yes but she said no\",\n",
        "        \"they walked together in peaceful silence\",\n",
        "        \"the door opened and he entered slowly\",\n",
        "        \"she spoke softly to the young child\",\n",
        "    ]\n",
        "    corpus = []\n",
        "    for _ in range(2000):\n",
        "        for p in patterns:\n",
        "            corpus.append(p.split())\n",
        "    random.shuffle(corpus)\n",
        "    vocab = set(w for s in corpus for w in s)\n",
        "    return corpus, vocab\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# RDT LANGUAGE MODEL\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class RDTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab, embedding_dim=128, alpha=1.5):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Vocabulary\n",
        "        self.word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "        for word in vocab:\n",
        "            self.word2idx[word] = len(self.word2idx)\n",
        "        self.idx2word = {v: k for k, v in self.word2idx.items()}\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # Shell organization\n",
        "        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        self.shells = defaultdict(list)\n",
        "        self.word_depth = {}\n",
        "        for word, idx in self.word2idx.items():\n",
        "            if idx >= 2:\n",
        "                depth = rdt_depth(idx, self.alpha)\n",
        "                self.shells[depth].append(word)\n",
        "                self.word_depth[word] = depth\n",
        "\n",
        "        # Embeddings are now learnable Parameters\n",
        "        self.embeddings = nn.ParameterDict(\n",
        "            {\n",
        "                w: nn.Parameter(\n",
        "                    torch.randn(embedding_dim, device=device) * 0.1\n",
        "                )\n",
        "                for w in self.word2idx.keys()\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # n-gram structures (not learnable)\n",
        "        self.bigrams = defaultdict(Counter)\n",
        "        self.trigrams = defaultdict(Counter)\n",
        "\n",
        "        print(f\"\\nâœ… RDT Model Initialized:\")\n",
        "        print(f\"   Vocabulary: {self.vocab_size} words\")\n",
        "        print(f\"   Embedding dim: {embedding_dim}\")\n",
        "        print(f\"   Alpha: {alpha}\")\n",
        "        for d in sorted(self.shells.keys()):\n",
        "            print(f\"      Shell {d}: {len(self.shells[d])} words\")\n",
        "            print(f\"         Sample: {self.shells[d][:6]}\")\n",
        "\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    # Training with Topological Adam\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def train_rdt(self, corpus, epochs=10, lr=1e-3):\n",
        "        print(\"\\nğŸ”¥ Training with Topological Adam (shell-aware geometry)\\n\")\n",
        "        optimizer = TopologicalAdam(self.embeddings.parameters(), lr=lr)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            random.shuffle(corpus)\n",
        "            total_loss = 0.0\n",
        "            for sentence in corpus:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # record n-grams (same as before)\n",
        "                for i in range(len(sentence) - 1):\n",
        "                    self.bigrams[sentence[i]][sentence[i + 1]] += 1\n",
        "                if len(sentence) >= 3:\n",
        "                    for i in range(len(sentence) - 2):\n",
        "                        self.trigrams[(sentence[i], sentence[i + 1])][\n",
        "                            sentence[i + 2]\n",
        "                        ] += 1\n",
        "\n",
        "                # build small loss from local word pairs\n",
        "                losses = []\n",
        "                for i, w in enumerate(sentence[:-1]):\n",
        "                    w_next = sentence[i + 1]\n",
        "                    if w in self.embeddings and w_next in self.embeddings:\n",
        "                        e1, e2 = self.embeddings[w], self.embeddings[w_next]\n",
        "                        sim = torch.dot(e1, e2) / (e1.norm() * e2.norm() + 1e-8)\n",
        "                        losses.append((1 - sim) ** 2)\n",
        "\n",
        "                if losses:\n",
        "                    loss = torch.stack(losses).mean()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}/{epochs}: \"\n",
        "                f\"loss={total_loss:.6f}, energy={optimizer.energy():.6e}\"\n",
        "            )\n",
        "\n",
        "        print(\"\\nâœ… Training Complete using Topological Adam!\")\n",
        "\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    # Generation (unchanged)\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def generate(self, start_text, max_length=15):\n",
        "        words = start_text.lower().split()\n",
        "        generated = list(words)\n",
        "        recent = set()\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            last = generated[-1]\n",
        "            if last not in self.word2idx:\n",
        "                break\n",
        "\n",
        "            # grammar first\n",
        "            if len(generated) >= 2:\n",
        "                key = (generated[-2], generated[-1])\n",
        "                if key in self.trigrams and self.trigrams[key]:\n",
        "                    cand = {w: c for w, c in self.trigrams[key].items() if w not in recent}\n",
        "                    if cand:\n",
        "                        nxt = random.choices(list(cand.keys()), weights=list(cand.values()))[0]\n",
        "                        generated.append(nxt)\n",
        "                        recent.add(nxt)\n",
        "                        if len(recent) > 5:\n",
        "                            recent.pop()\n",
        "                        continue\n",
        "\n",
        "            scores = {}\n",
        "            if last in self.bigrams:\n",
        "                total = sum(self.bigrams[last].values())\n",
        "                for w, c in self.bigrams[last].items():\n",
        "                    penalty = 0.1 if w in recent else 1.0\n",
        "                    scores[w] = (c / total) * 0.6 * penalty\n",
        "\n",
        "            last_shell = self.word_depth.get(last, 0)\n",
        "            last_emb = self.embeddings[last]\n",
        "            for off in [0, 1, -1]:\n",
        "                check = last_shell + off\n",
        "                if check in self.shells:\n",
        "                    for w in self.shells[check]:\n",
        "                        if w == last or w in recent:\n",
        "                            continue\n",
        "                        e = self.embeddings[w]\n",
        "                        sim = (\n",
        "                            torch.dot(last_emb, e)\n",
        "                            / (last_emb.norm() * e.norm() + 1e-8)\n",
        "                        ).item()\n",
        "                        if self.word_depth.get(w, 0) == last_shell:\n",
        "                            sim *= 1.5\n",
        "                        scores[w] = scores.get(w, 0) + max(0, sim) * 0.4\n",
        "\n",
        "            if not scores:\n",
        "                break\n",
        "            sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            top3 = sorted_words[:3]\n",
        "            nxt = random.choice(top3)[0] if len(top3) > 1 else sorted_words[0][0]\n",
        "            generated.append(nxt)\n",
        "            recent.add(nxt)\n",
        "            if len(recent) > 5:\n",
        "                recent.pop()\n",
        "            if len(generated) >= 4 and len(set(generated[-4:])) <= 2:\n",
        "                break\n",
        "        return \" \".join(generated)\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# MAIN EXECUTION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 70)\n",
        "    print(\"RDT LANGUAGE MODEL WITH TOPOLOGICAL ADAM\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    corpus, vocab = generate_corpus()\n",
        "    print(f\"\\nğŸ“š Training Data: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "\n",
        "    model = RDTLanguageModel(vocab, embedding_dim=128, alpha=1.5).to(device)\n",
        "    model.train_rdt(corpus, epochs=10, lr=1e-3)\n",
        "\n",
        "    prompts = [\"the man walked\", \"she was happy\", \"in the morning\", \"the old king\", \"once there was\"]\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"TEXT GENERATION\")\n",
        "    print(\"=\" * 70)\n",
        "    for p in prompts:\n",
        "        print(f\"\\nPrompt: '{p}'\")\n",
        "        for i in range(3):\n",
        "            print(f\"  {i+1}. {model.generate(p, max_length=12)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install topological-adam --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6VdIX_n93nE",
        "outputId": "03696b97-3071-451c-b8b9-908060eade9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting topological-adam\n",
            "  Downloading topological_adam-1.0.0-py3-none-any.whl.metadata (326 bytes)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from topological-adam) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->topological-adam) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->topological-adam) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->topological-adam) (3.0.3)\n",
            "Downloading topological_adam-1.0.0-py3-none-any.whl (2.7 kB)\n",
            "Installing collected packages: topological-adam\n",
            "Successfully installed topological-adam-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "RDT LANGUAGE MODEL + Topological Adam Optimizer Integration\n",
        "Author: Steven Reid\n",
        "License: Apache 2.0\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter\n",
        "from topological_adam import TopologicalAdam  # pip install topological-adam\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Using: {device}\")\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# RDT MATH\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    \"\"\"Doubly-logarithmic depth calculation\"\"\"\n",
        "    if n < 2:\n",
        "        return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d:\n",
        "            break\n",
        "        x //= d\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "\n",
        "def generate_corpus():\n",
        "    patterns = [\n",
        "        \"the man walked to the house\",\n",
        "        \"the woman went to the market\",\n",
        "        \"the child ran to the river\",\n",
        "        \"he was happy and she was sad\",\n",
        "        \"they found the truth and left quickly\",\n",
        "        \"in the morning he woke up early\",\n",
        "        \"at night she went to sleep\",\n",
        "        \"the old king ruled the land wisely\",\n",
        "        \"the young prince sought great adventure\",\n",
        "        \"once there was a wise teacher\",\n",
        "        \"the forest was dark and very quiet\",\n",
        "        \"he said yes but she said no\",\n",
        "        \"they walked together in peaceful silence\",\n",
        "        \"the door opened and he entered slowly\",\n",
        "        \"she spoke softly to the young child\",\n",
        "    ]\n",
        "    corpus = []\n",
        "    for _ in range(2000):\n",
        "        for p in patterns:\n",
        "            corpus.append(p.split())\n",
        "    random.shuffle(corpus)\n",
        "    vocab = set(w for s in corpus for w in s)\n",
        "    return corpus, vocab\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# RDT LANGUAGE MODEL\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "class RDTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab, embedding_dim=128, alpha=1.5):\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Vocabulary\n",
        "        self.word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
        "        for word in vocab:\n",
        "            self.word2idx[word] = len(self.word2idx)\n",
        "        self.idx2word = {v: k for k, v in self.word2idx.items()}\n",
        "        self.vocab_size = len(self.word2idx)\n",
        "\n",
        "        # Shell organization\n",
        "        self.shells = defaultdict(list)\n",
        "        self.word_depth = {}\n",
        "        for word, idx in self.word2idx.items():\n",
        "            if idx >= 2:\n",
        "                depth = rdt_depth(idx, self.alpha)\n",
        "                self.shells[depth].append(word)\n",
        "                self.word_depth[word] = depth\n",
        "\n",
        "        # Embeddings (safe keys to avoid collisions with nn.Module attrs)\n",
        "        safe = {}\n",
        "        for w in self.word2idx.keys():\n",
        "            safe_key = f\"w_{w}\"\n",
        "            safe[safe_key] = nn.Parameter(\n",
        "                torch.randn(embedding_dim, device=device) * 0.1\n",
        "            )\n",
        "        self.embeddings = nn.ParameterDict(safe)\n",
        "        self._embed_lookup = {\n",
        "            w: self.embeddings[f\"w_{w}\"] for w in self.word2idx.keys()\n",
        "        }\n",
        "\n",
        "        # n-gram counters\n",
        "        self.bigrams = defaultdict(Counter)\n",
        "        self.trigrams = defaultdict(Counter)\n",
        "\n",
        "        print(f\"\\nâœ… RDT Model Initialized:\")\n",
        "        print(f\"   Vocabulary: {self.vocab_size} words\")\n",
        "        print(f\"   Embedding dim: {embedding_dim}\")\n",
        "        print(f\"   Alpha: {alpha}\")\n",
        "        for d in sorted(self.shells.keys()):\n",
        "            print(f\"      Shell {d}: {len(self.shells[d])} words\")\n",
        "            print(f\"         Sample: {self.shells[d][:6]}\")\n",
        "\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    # Training with Topological Adam\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def train_rdt(self, corpus, epochs=10, lr=1e-3):\n",
        "        print(\"\\nğŸ”¥ Training with Topological Adam (shell-aware geometry)\\n\")\n",
        "        optimizer = TopologicalAdam(self.embeddings.parameters(), lr=lr)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            random.shuffle(corpus)\n",
        "            total_loss = 0.0\n",
        "\n",
        "            for sentence in corpus:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # record n-grams\n",
        "                for i in range(len(sentence) - 1):\n",
        "                    self.bigrams[sentence[i]][sentence[i + 1]] += 1\n",
        "                if len(sentence) >= 3:\n",
        "                    for i in range(len(sentence) - 2):\n",
        "                        self.trigrams[(sentence[i], sentence[i + 1])][\n",
        "                            sentence[i + 2]\n",
        "                        ] += 1\n",
        "\n",
        "                # compute loss from local word pairs\n",
        "                losses = []\n",
        "                for i, w in enumerate(sentence[:-1]):\n",
        "                    w_next = sentence[i + 1]\n",
        "                    if w in self._embed_lookup and w_next in self._embed_lookup:\n",
        "                        e1 = self._embed_lookup[w]\n",
        "                        e2 = self._embed_lookup[w_next]\n",
        "                        sim = torch.dot(e1, e2) / (e1.norm() * e2.norm() + 1e-8)\n",
        "                        losses.append((1 - sim) ** 2)\n",
        "\n",
        "                if losses:\n",
        "                    loss = torch.stack(losses).mean()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "            print(\n",
        "                f\"Epoch {epoch+1}/{epochs}: \"\n",
        "                f\"loss={total_loss:.6f}, energy={optimizer.energy():.6e}\"\n",
        "            )\n",
        "\n",
        "        print(\"\\nâœ… Training Complete using Topological Adam!\")\n",
        "\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    # Generation (unchanged)\n",
        "    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def generate(self, start_text, max_length=15):\n",
        "        words = start_text.lower().split()\n",
        "        generated = list(words)\n",
        "        recent = set()\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            last = generated[-1]\n",
        "            if last not in self.word2idx:\n",
        "                break\n",
        "\n",
        "            # grammar first\n",
        "            if len(generated) >= 2:\n",
        "                key = (generated[-2], generated[-1])\n",
        "                if key in self.trigrams and self.trigrams[key]:\n",
        "                    cand = {\n",
        "                        w: c\n",
        "                        for w, c in self.trigrams[key].items()\n",
        "                        if w not in recent\n",
        "                    }\n",
        "                    if cand:\n",
        "                        nxt = random.choices(\n",
        "                            list(cand.keys()), weights=list(cand.values())\n",
        "                        )[0]\n",
        "                        generated.append(nxt)\n",
        "                        recent.add(nxt)\n",
        "                        if len(recent) > 5:\n",
        "                            recent.pop()\n",
        "                        continue\n",
        "\n",
        "            scores = {}\n",
        "            if last in self.bigrams:\n",
        "                total = sum(self.bigrams[last].values())\n",
        "                for w, c in self.bigrams[last].items():\n",
        "                    penalty = 0.1 if w in recent else 1.0\n",
        "                    scores[w] = (c / total) * 0.6 * penalty\n",
        "\n",
        "            last_shell = self.word_depth.get(last, 0)\n",
        "            last_emb = self._embed_lookup[last]\n",
        "            for off in [0, 1, -1]:\n",
        "                check = last_shell + off\n",
        "                if check in self.shells:\n",
        "                    for w in self.shells[check]:\n",
        "                        if w == last or w in recent:\n",
        "                            continue\n",
        "                        e = self._embed_lookup[w]\n",
        "                        sim = (\n",
        "                            torch.dot(last_emb, e)\n",
        "                            / (last_emb.norm() * e.norm() + 1e-8)\n",
        "                        ).item()\n",
        "                        if self.word_depth.get(w, 0) == last_shell:\n",
        "                            sim *= 1.5\n",
        "                        scores[w] = scores.get(w, 0) + max(0, sim) * 0.4\n",
        "\n",
        "            if not scores:\n",
        "                break\n",
        "            sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "            top3 = sorted_words[:3]\n",
        "            nxt = random.choice(top3)[0] if len(top3) > 1 else sorted_words[0][0]\n",
        "            generated.append(nxt)\n",
        "            recent.add(nxt)\n",
        "            if len(recent) > 5:\n",
        "                recent.pop()\n",
        "            if len(generated) >= 4 and len(set(generated[-4:])) <= 2:\n",
        "                break\n",
        "        return \" \".join(generated)\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# MAIN EXECUTION\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 70)\n",
        "    print(\"RDT LANGUAGE MODEL WITH TOPOLOGICAL ADAM\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    corpus, vocab = generate_corpus()\n",
        "    print(f\"\\nğŸ“š Training Data: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "\n",
        "    model = RDTLanguageModel(vocab, embedding_dim=128, alpha=1.5).to(device)\n",
        "    model.train_rdt(corpus, epochs=10, lr=1e-3)\n",
        "\n",
        "    prompts = [\n",
        "        \"the man walked\",\n",
        "        \"she was happy\",\n",
        "        \"in the morning\",\n",
        "        \"the old king\",\n",
        "        \"once there was\",\n",
        "    ]\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"TEXT GENERATION\")\n",
        "    print(\"=\" * 70)\n",
        "    for p in prompts:\n",
        "        print(f\"\\nPrompt: '{p}'\")\n",
        "        for i in range(3):\n",
        "            print(f\"  {i+1}. {model.generate(p, max_length=12)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQflw84p_Zg0",
        "outputId": "bfbbf2de-886b-4ee7-9f15-64a83e6532b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Using: cuda\n",
            "======================================================================\n",
            "RDT LANGUAGE MODEL WITH TOPOLOGICAL ADAM\n",
            "======================================================================\n",
            "\n",
            "ğŸ“š Training Data: 30,000 sentences, 62 words\n",
            "\n",
            "âœ… RDT Model Initialized:\n",
            "   Vocabulary: 64 words\n",
            "   Embedding dim: 128\n",
            "   Alpha: 1.5\n",
            "      Shell 1: 2 words\n",
            "         Sample: ['they', 'together']\n",
            "      Shell 2: 11 words\n",
            "         Sample: ['woke', 'said', 'once', 'ran', 'woman', 'market']\n",
            "      Shell 3: 49 words\n",
            "         Sample: ['silence', 'entered', 'at', 'slowly', 'and', 'adventure']\n",
            "\n",
            "ğŸ”¥ Training with Topological Adam (shell-aware geometry)\n",
            "\n",
            "Epoch 1/10: loss=706.582346, energy=6.722811e-03\n",
            "Epoch 2/10: loss=1.867584, energy=6.722930e-03\n",
            "Epoch 3/10: loss=0.216469, energy=6.722835e-03\n",
            "Epoch 4/10: loss=0.032107, energy=5.762563e-03\n",
            "Epoch 5/10: loss=0.005049, energy=4.802022e-03\n",
            "Epoch 6/10: loss=0.000831, energy=5.762650e-03\n",
            "Epoch 7/10: loss=0.000143, energy=4.802027e-03\n",
            "Epoch 8/10: loss=0.000027, energy=5.762603e-03\n",
            "Epoch 9/10: loss=0.000006, energy=6.723121e-03\n",
            "Epoch 10/10: loss=0.000002, energy=4.802164e-03\n",
            "\n",
            "âœ… Training Complete using Topological Adam!\n",
            "\n",
            "======================================================================\n",
            "TEXT GENERATION\n",
            "======================================================================\n",
            "\n",
            "Prompt: 'the man walked'\n",
            "  1. the man walked to the river and he entered slowly and she was sad was\n",
            "  2. the man walked to the house in young prince sought great adventure child in peaceful\n",
            "  3. the man walked to the young child she and he entered slowly was happy and\n",
            "\n",
            "Prompt: 'she was happy'\n",
            "  1. she was happy and she was sad left he happy and she the child ran\n",
            "  2. she was happy and she was sad left happy he and happy she the house\n",
            "  3. she was happy and she was sad happy left and he entered slowly left was\n",
            "\n",
            "Prompt: 'in the morning'\n",
            "  1. in the morning he woke up early and she was sad and left quickly went\n",
            "  2. in the morning he woke up early she spoke softly to the young prince sought\n",
            "  3. in the morning he woke up early she and left quickly said no was happy\n",
            "\n",
            "Prompt: 'the old king'\n",
            "  1. the old king ruled the land wisely and left quickly walked together in peaceful silence\n",
            "  2. the old king ruled the land wisely opened and he entered slowly was happy and\n",
            "  3. the old king ruled the land wisely she was sad happy was dark and very\n",
            "\n",
            "Prompt: 'once there was'\n",
            "  1. once there was a wise teacher was happy and she and he entered slowly but\n",
            "  2. once there was a wise teacher was happy and she spoke softly to the market\n",
            "  3. once there was a wise teacher was dark and very quiet he she and the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install topological-adam --quiet"
      ],
      "metadata": {
        "id": "cDRrro1sGdL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  ğŸ”¬  RDT + Topological Adam + Neural Network Integration Test\n",
        "# ===============================================================\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np, math, random\n",
        "from collections import defaultdict, Counter\n",
        "from topological_adam import TopologicalAdam     # your installed package\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Using: {device}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1.  RDT MATH  (unchanged)\n",
        "# ===============================================================\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    if n < 2: return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d: break\n",
        "        x //= d; depth += 1\n",
        "    return depth\n",
        "\n",
        "# ===============================================================\n",
        "# 2.  DATA\n",
        "# ===============================================================\n",
        "def generate_corpus():\n",
        "    patterns = [\n",
        "        \"the man walked to the house\",\n",
        "        \"the woman went to the market\",\n",
        "        \"the child ran to the river\",\n",
        "        \"he was happy and she was sad\",\n",
        "        \"they found the truth and left quickly\",\n",
        "        \"in the morning he woke up early\",\n",
        "        \"the old king ruled the land wisely\",\n",
        "        \"once there was a wise teacher\",\n",
        "    ]\n",
        "    corpus = [p.split() for p in patterns * 4000]\n",
        "    random.shuffle(corpus)\n",
        "    vocab = sorted(set(word for sent in corpus for word in sent))\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus, vocab = generate_corpus()\n",
        "print(f\"ğŸ“š Training Data: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "\n",
        "# ===============================================================\n",
        "# 3.  RDT LANGUAGE ENCODER + NEURAL NET HEAD\n",
        "# ===============================================================\n",
        "class RDTNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Combines:\n",
        "      â€¢ RDT shell embeddings\n",
        "      â€¢ Topological Adam optimizer physics\n",
        "      â€¢ GRU neural network head\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab, emb_dim=128, hidden=256, alpha=1.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
        "        self.vocab_size = len(vocab)\n",
        "\n",
        "        # --- RDT shell geometry ---\n",
        "        depths = [rdt_depth(i+2, alpha) for i in range(self.vocab_size)]\n",
        "        self.shell_index = torch.tensor(depths, device=device)\n",
        "        self.embed = nn.Embedding(self.vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden, batch_first=True)\n",
        "        self.fc  = nn.Linear(hidden, self.vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.embed(x)\n",
        "        out, _ = self.rnn(e)\n",
        "        return self.fc(out)\n",
        "\n",
        "# ===============================================================\n",
        "# 4.  TRAINING LOOP WITH TOPOLOGICAL ADAM\n",
        "# ===============================================================\n",
        "def encode_sentence(sent, word2idx, maxlen=8):\n",
        "    idxs = [word2idx[w] for w in sent if w in word2idx]\n",
        "    pad = [0]*(maxlen-len(idxs))\n",
        "    return torch.tensor([idxs+pad], device=device)\n",
        "\n",
        "def train_model(model, corpus, epochs=10, lr=1e-3):\n",
        "    optimizer = TopologicalAdam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss_log, energy_log = [], []\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        random.shuffle(corpus)\n",
        "        total_loss = 0.0\n",
        "        for sent in corpus:\n",
        "            if len(sent) < 2: continue\n",
        "            x = encode_sentence(sent[:-1], model.word2idx)\n",
        "            y = encode_sentence(sent[1:], model.word2idx).view(-1)\n",
        "            out = model(x).view(-1, model.vocab_size)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        mean_loss = total_loss / len(corpus)\n",
        "        mean_energy = optimizer.energy()\n",
        "        loss_log.append(mean_loss)\n",
        "        energy_log.append(mean_energy)\n",
        "        print(f\"Epoch {ep:2d}: loss={mean_loss:.6f}  energy={mean_energy:.6e}\")\n",
        "\n",
        "    return loss_log, energy_log\n",
        "\n",
        "# ===============================================================\n",
        "# 5.  RUN EXPERIMENT\n",
        "# ===============================================================\n",
        "model = RDTNet(vocab).to(device)\n",
        "losses, energies = train_model(model, corpus, epochs=10, lr=1e-3)\n",
        "print(\"âœ… Training complete â€” RDT + GRU + Topological Adam.\")\n",
        "\n",
        "# ===============================================================\n",
        "# 6.  PLOT RESULTS\n",
        "# ===============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(9,4))\n",
        "plt.subplot(1,2,1); plt.plot(losses); plt.title(\"Loss\"); plt.xlabel(\"Epoch\")\n",
        "plt.subplot(1,2,2); plt.plot(energies); plt.title(\"Energy\"); plt.xlabel(\"Epoch\")\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "QzMsgRFablZ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "b7efb10d-5060-4f6b-f44d-6183320c0f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Using: cpu\n",
            "ğŸ“š Training Data: 32,000 sentences, 37 words\n",
            "Epoch  1: loss=0.093509  energy=6.722810e-03\n",
            "Epoch  2: loss=0.089060  energy=6.722810e-03\n",
            "Epoch  3: loss=0.088955  energy=6.722808e-03\n",
            "Epoch  4: loss=0.089000  energy=6.722814e-03\n",
            "Epoch  5: loss=0.088966  energy=6.722814e-03\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2382759619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# ===============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRDTNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… Training complete â€” RDT + GRU + Topological Adam.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2382759619.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, corpus, epochs, lr)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m                             )\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/topological_adam/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;31m# Adam update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mm_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mv_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  COMPLETE RDT LANGUAGE MODEL\n",
        "#  ALL COMPONENTS: RDT + TNN + Topological Adam + Spatial Index + MHD Insights\n",
        "# ===============================================================\n",
        "!pip install topological-adam --quiet\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np, math, random\n",
        "from collections import defaultdict\n",
        "from topological_adam import TopologicalAdam\n",
        "from matplotlib import pyplot as plt\n",
        "from numba import njit\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Device: {device}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1. YOUR RDT MATH (unchanged)\n",
        "# ===============================================================\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    if n < 2: return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d: break\n",
        "        x //= d\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def rdt_grid_size(n, alpha=1.5):\n",
        "    if n <= 1:\n",
        "        return 2\n",
        "    d = max(2, int(np.log(n + 1) ** alpha))\n",
        "    return min(d, 32)\n",
        "\n",
        "# ===============================================================\n",
        "# 2. YOUR RDT SPATIAL INDEX (unchanged)\n",
        "# ===============================================================\n",
        "class RDTEmbeddingIndex:\n",
        "    def __init__(self, vocab_size, embedding_dim, alpha=1.5):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.alpha = alpha\n",
        "        self.shells = defaultdict(list)\n",
        "        self.word_depth = {}\n",
        "        for idx in range(vocab_size):\n",
        "            depth = rdt_depth(idx, alpha)\n",
        "            self.shells[depth].append(idx)\n",
        "            self.word_depth[idx] = depth\n",
        "        self.shell_grid_sizes = {}\n",
        "        for depth, words in self.shells.items():\n",
        "            n = len(words)\n",
        "            self.shell_grid_sizes[depth] = rdt_grid_size(n, alpha)\n",
        "        print(f\"\\nğŸ”¬ RDT Spatial Index:\")\n",
        "        for depth in sorted(self.shells.keys()):\n",
        "            n = len(self.shells[depth])\n",
        "            g = self.shell_grid_sizes[depth]\n",
        "            print(f\"   Shell {depth}: {n} words, grid {g}Ã—{g}\")\n",
        "    def find_nearest_in_shell(self, embedding, target_shell, embeddings_dict, k=5):\n",
        "        if target_shell not in self.shells: return []\n",
        "        candidates = self.shells[target_shell]\n",
        "        distances = []\n",
        "        for word_idx in candidates:\n",
        "            emb = embeddings_dict[word_idx]\n",
        "            sim = F.cosine_similarity(embedding.unsqueeze(0), emb.unsqueeze(0))\n",
        "            distances.append((word_idx, sim.item()))\n",
        "        distances.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [idx for idx, _ in distances[:k]]\n",
        "    def hierarchical_search(self, embedding, current_word_idx, embeddings_dict, k=10):\n",
        "        current_shell = self.word_depth.get(current_word_idx, 0)\n",
        "        candidates = self.find_nearest_in_shell(embedding, current_shell, embeddings_dict, k=k)\n",
        "        if len(candidates) < k:\n",
        "            for offset in [1, -1, 2, -2]:\n",
        "                nearby_shell = current_shell + offset\n",
        "                if nearby_shell in self.shells:\n",
        "                    more = self.find_nearest_in_shell(\n",
        "                        embedding, nearby_shell, embeddings_dict, k=k-len(candidates)\n",
        "                    )\n",
        "                    candidates.extend(more)\n",
        "                    if len(candidates) >= k: break\n",
        "        return candidates[:k]\n",
        "\n",
        "# ===============================================================\n",
        "# 3. DATA (unchanged)\n",
        "# ===============================================================\n",
        "def generate_rich_corpus():\n",
        "    subjects = ['the man','the woman','the child','the king','the queen','the soldier','the merchant','the teacher','the old man','the young woman','a stranger','the traveler','the farmer','the priest','the warrior','the beggar','the noble']\n",
        "    verbs = ['walked','ran','went','came','spoke','thought','found','discovered','remembered','believed','understood','left','arrived','departed','searched','wondered','feared','hoped','carried','held','took','gave','brought','sent']\n",
        "    locations = ['to the house','to the market','to the river','to the forest','to the castle','through the valley','across the land','to the mountain','to the sea','to the village','to the city','through the door','into the darkness','toward the light','beyond the horizon','near the gate']\n",
        "    adjectives = ['happy','sad','brave','wise','afraid','calm','strong','gentle','proud','humble','kind','cruel','young','old','rich','poor','noble','simple','great','small']\n",
        "    times = ['in the morning','at night','at dawn','at dusk','yesterday','long ago','one day','when winter came','when spring arrived','at midnight','before sunrise','after sunset']\n",
        "    objects = ['a sword','a book','a letter','a key','a treasure','a secret','a truth','a dream','a memory','a promise','a gift']\n",
        "    corpus = []\n",
        "    for _ in range(4000):\n",
        "        s,v,l = random.choice(subjects),random.choice(verbs),random.choice(locations)\n",
        "        corpus.append(f\"{s} {v} {l}\".split())\n",
        "    for _ in range(3000):\n",
        "        s,adj = random.choice(subjects),random.choice(adjectives)\n",
        "        corpus.append(f\"{s} was {adj}\".split())\n",
        "    for _ in range(3000):\n",
        "        t,s,v = random.choice(times),random.choice(subjects),random.choice(verbs)\n",
        "        corpus.append(f\"{t} {s} {v}\".split())\n",
        "    for _ in range(2000):\n",
        "        s=random.choice(subjects); v=random.choice(['found','held','carried','brought','took']); o=random.choice(objects)\n",
        "        corpus.append(f\"{s} {v} {o}\".split())\n",
        "    for _ in range(2000):\n",
        "        s1,adj1=random.choice(subjects),random.choice(adjectives)\n",
        "        s2,adj2=random.choice(['he','she','they']),random.choice(adjectives)\n",
        "        corpus.append(f\"{s1} was {adj1} and {s2} was {adj2}\".split())\n",
        "    for _ in range(2000):\n",
        "        s,adj=random.choice(['the','a']),random.choice(adjectives)\n",
        "        noun=random.choice(['man','woman','child','king','soldier'])\n",
        "        v=random.choice(verbs)\n",
        "        corpus.append(f\"{s} {adj} {noun} {v}\".split())\n",
        "    random.shuffle(corpus)\n",
        "    vocab = sorted(set(word for sent in corpus for word in sent))\n",
        "    print(f\"ğŸ“š Corpus: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus, vocab = generate_rich_corpus()\n",
        "\n",
        "# ===============================================================\n",
        "# 4. TOPOLOGICAL NEURAL NETWORK (patched E/C scaling fix)\n",
        "# ===============================================================\n",
        "class TopologicalNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=256, hidden_dim=512, output_dim=256, lambda_topo=1.0):\n",
        "        super().__init__()\n",
        "        self.lambda_topo = lambda_topo\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.energy = self.coupling = self.stability = 0.0\n",
        "        self.energy_ratio = 1.0\n",
        "\n",
        "    def compute_topological_terms(self, activations):\n",
        "        eps = 1e-8\n",
        "        E = torch.mean(activations ** 2)\n",
        "        grad = torch.autograd.grad(E, activations, retain_graph=True, create_graph=True, allow_unused=True)\n",
        "        if grad[0] is None:\n",
        "            C = E\n",
        "        else:\n",
        "            C_raw = torch.mean(grad[0] ** 2)\n",
        "            N = activations.numel()\n",
        "            scale = 4.0 / (N ** 2)\n",
        "            C = C_raw / (scale + eps)\n",
        "        ratio = E / (C + eps)\n",
        "        ratio_clamped = torch.clamp(ratio, 0.25, 4.0)\n",
        "        E_d, C_d, S_d = E.detach(), C.detach(), torch.abs(ratio - 1.0).detach()\n",
        "        return E_d, C_d, S_d, ratio_clamped\n",
        "\n",
        "    def forward(self, x):\n",
        "        reshaped = False\n",
        "        if len(x.shape) == 3:\n",
        "            b, s, d = x.shape\n",
        "            x = x.reshape(b * s, d)\n",
        "            reshaped = True\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        h2_norm = self.layer_norm(h2)\n",
        "        out = self.fc3(h2_norm)\n",
        "        if self.training:\n",
        "            E_d, C_d, S_d, ratio_for_ctrl = self.compute_topological_terms(h2_norm)\n",
        "            self.energy, self.coupling, self.stability = E_d.item(), C_d.item(), S_d.item()\n",
        "            if not hasattr(self, \"_ratio_ema\"):\n",
        "                self._ratio_ema = ratio_for_ctrl.detach()\n",
        "            self._ratio_ema = 0.9 * self._ratio_ema + 0.1 * ratio_for_ctrl.detach()\n",
        "            correction = self.lambda_topo * torch.log(self._ratio_ema + 1e-8)\n",
        "            out = out + correction * torch.tanh(out)\n",
        "        if reshaped:\n",
        "            out = out.reshape(b, s, -1)\n",
        "        return out\n",
        "\n",
        "# ===============================================================\n",
        "# 5â€“9  REMAIN UNCHANGED (your full system, loss, optimizer, visualization)\n",
        "# ===============================================================\n",
        "# ... [keep all remaining code from your working version unchanged below this line]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "-e_i6jCCyXNW",
        "outputId": "5a31ffb0-055b-47a9-c7a1-198ddf95950e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1888199140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install topological-adam --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2668\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;31m# Enable CUDA Sanitizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSymBool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymFloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m from torch._decomp import (\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0m_add_op_to_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0m_convert_out_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;31m# populate the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_refs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_decomp/decompositions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta_registrations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m abs = _make_elementwise_unary_prim(\n\u001b[0m\u001b[1;32m    526\u001b[0m     \u001b[0;34m\"abs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mimpl_aten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m_make_elementwise_unary_prim\u001b[0;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     return _make_prim(\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{name}(Tensor self) -> Tensor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prim_elementwise_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_promotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_promotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_prims/__init__.py\u001b[0m in \u001b[0;36m_make_prim\u001b[0;34m(schema, return_type, meta, impl_aten, doc, tags, use_old_custom_ops_api, register_conj_neg_fallthrough)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_write\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         ]\n\u001b[0;32m--> 321\u001b[0;31m         prim_def = torch.library.custom_op(\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;34m\"prims::\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0m_prim_impl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/custom_ops.py\u001b[0m in \u001b[0;36mcustom_op\u001b[0;34m(name, fn, mutates_args, device_types, schema, tags)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/custom_ops.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomOpDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# Check that schema's alias annotations match those of `mutates_args`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/custom_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, namespace, name, schema, fn, tags)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_library_allowing_overwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_to_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_disabled_kernel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mOPDEFS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qualname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/custom_ops.py\u001b[0m in \u001b[0;36m_register_to_dispatcher\u001b[0;34m(self, tags)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abstract_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_fake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mautograd_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_autograd_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opoverload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m_register_fake\u001b[0;34m(self, op_name, fn, _stacklevel, allow_override)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_stacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mcaller_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_library/utils.py\u001b[0m in \u001b[0;36mget_source\u001b[0;34m(stacklevel)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0metc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetframeinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{frame.filename}:{frame.lineno}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1718\u001b[0;31m             \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindsource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source code not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/inspect.py\u001b[0m in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;31m# Always map to the name the module knows itself by\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             modulesbyfile[f] = modulesbyfile[\n\u001b[0;32m-> 1016\u001b[0;31m                 os.path.realpath(f)] = module.__name__\n\u001b[0m\u001b[1;32m   1017\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodulesbyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodulesbyfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/posixpath.py\u001b[0m in \u001b[0;36mrealpath\u001b[0;34m(filename, strict)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/posixpath.py\u001b[0m in \u001b[0;36m_joinrealpath\u001b[0;34m(path, rest, strict, seen)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  COMPLETE RDT LANGUAGE MODEL\n",
        "#  ALL COMPONENTS: RDT + TNN + Topological Adam + Spatial Index + MHD Insights\n",
        "#  (includes corrected E/C normalization)\n",
        "# ===============================================================\n",
        "!pip install topological-adam --quiet\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np, math, random\n",
        "from collections import defaultdict\n",
        "from topological_adam import TopologicalAdam\n",
        "from matplotlib import pyplot as plt\n",
        "from numba import njit\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Device: {device}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1. YOUR RDT MATH\n",
        "# ===============================================================\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    if n < 2: return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d: break\n",
        "        x //= d\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def rdt_grid_size(n, alpha=1.5):\n",
        "    if n <= 1:\n",
        "        return 2\n",
        "    d = max(2, int(np.log(n + 1) ** alpha))\n",
        "    return min(d, 32)\n",
        "\n",
        "# ===============================================================\n",
        "# 2. RDT SPATIAL INDEX\n",
        "# ===============================================================\n",
        "class RDTEmbeddingIndex:\n",
        "    def __init__(self, vocab_size, embedding_dim, alpha=1.5):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.alpha = alpha\n",
        "        self.shells = defaultdict(list)\n",
        "        self.word_depth = {}\n",
        "        for idx in range(vocab_size):\n",
        "            depth = rdt_depth(idx, alpha)\n",
        "            self.shells[depth].append(idx)\n",
        "            self.word_depth[idx] = depth\n",
        "        self.shell_grid_sizes = {}\n",
        "        for depth, words in self.shells.items():\n",
        "            n = len(words)\n",
        "            self.shell_grid_sizes[depth] = rdt_grid_size(n, alpha)\n",
        "        print(f\"\\nğŸ”¬ RDT Spatial Index:\")\n",
        "        for depth in sorted(self.shells.keys()):\n",
        "            n = len(self.shells[depth])\n",
        "            g = self.shell_grid_sizes[depth]\n",
        "            print(f\"   Shell {depth}: {n} words, grid {g}Ã—{g}\")\n",
        "\n",
        "    def find_nearest_in_shell(self, embedding, target_shell, embeddings_dict, k=5):\n",
        "        if target_shell not in self.shells:\n",
        "            return []\n",
        "        candidates = self.shells[target_shell]\n",
        "        distances = []\n",
        "        for word_idx in candidates:\n",
        "            emb = embeddings_dict[word_idx]\n",
        "            sim = F.cosine_similarity(embedding.unsqueeze(0), emb.unsqueeze(0))\n",
        "            distances.append((word_idx, sim.item()))\n",
        "        distances.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [idx for idx, _ in distances[:k]]\n",
        "\n",
        "    def hierarchical_search(self, embedding, current_word_idx, embeddings_dict, k=10):\n",
        "        current_shell = self.word_depth.get(current_word_idx, 0)\n",
        "        candidates = self.find_nearest_in_shell(embedding, current_shell, embeddings_dict, k=k)\n",
        "        if len(candidates) < k:\n",
        "            for offset in [1, -1, 2, -2]:\n",
        "                nearby_shell = current_shell + offset\n",
        "                if nearby_shell in self.shells:\n",
        "                    more = self.find_nearest_in_shell(\n",
        "                        embedding, nearby_shell, embeddings_dict, k=k-len(candidates)\n",
        "                    )\n",
        "                    candidates.extend(more)\n",
        "                    if len(candidates) >= k:\n",
        "                        break\n",
        "        return candidates[:k]\n",
        "\n",
        "# ===============================================================\n",
        "# 3. DATA\n",
        "# ===============================================================\n",
        "def generate_rich_corpus():\n",
        "    subjects = ['the man','the woman','the child','the king','the queen','the soldier','the merchant','the teacher','the old man','the young woman','a stranger','the traveler','the farmer','the priest','the warrior','the beggar','the noble']\n",
        "    verbs = ['walked','ran','went','came','spoke','thought','found','discovered','remembered','believed','understood','left','arrived','departed','searched','wondered','feared','hoped','carried','held','took','gave','brought','sent']\n",
        "    locations = ['to the house','to the market','to the river','to the forest','to the castle','through the valley','across the land','to the mountain','to the sea','to the village','to the city','through the door','into the darkness','toward the light','beyond the horizon','near the gate']\n",
        "    adjectives = ['happy','sad','brave','wise','afraid','calm','strong','gentle','proud','humble','kind','cruel','young','old','rich','poor','noble','simple','great','small']\n",
        "    times = ['in the morning','at night','at dawn','at dusk','yesterday','long ago','one day','when winter came','when spring arrived','at midnight','before sunrise','after sunset']\n",
        "    objects = ['a sword','a book','a letter','a key','a treasure','a secret','a truth','a dream','a memory','a promise','a gift']\n",
        "    corpus = []\n",
        "    for _ in range(4000):\n",
        "        s,v,l = random.choice(subjects),random.choice(verbs),random.choice(locations)\n",
        "        corpus.append(f\"{s} {v} {l}\".split())\n",
        "    for _ in range(3000):\n",
        "        s,adj = random.choice(subjects),random.choice(adjectives)\n",
        "        corpus.append(f\"{s} was {adj}\".split())\n",
        "    for _ in range(3000):\n",
        "        t,s,v = random.choice(times),random.choice(subjects),random.choice(verbs)\n",
        "        corpus.append(f\"{t} {s} {v}\".split())\n",
        "    for _ in range(2000):\n",
        "        s=random.choice(subjects); v=random.choice(['found','held','carried','brought','took']); o=random.choice(objects)\n",
        "        corpus.append(f\"{s} {v} {o}\".split())\n",
        "    for _ in range(2000):\n",
        "        s1,adj1=random.choice(subjects),random.choice(adjectives)\n",
        "        s2,adj2=random.choice(['he','she','they']),random.choice(adjectives)\n",
        "        corpus.append(f\"{s1} was {adj1} and {s2} was {adj2}\".split())\n",
        "    for _ in range(2000):\n",
        "        s,adj=random.choice(['the','a']),random.choice(adjectives)\n",
        "        noun=random.choice(['man','woman','child','king','soldier'])\n",
        "        v=random.choice(verbs)\n",
        "        corpus.append(f\"{s} {adj} {noun} {v}\".split())\n",
        "    random.shuffle(corpus)\n",
        "    vocab = sorted(set(word for sent in corpus for word in sent))\n",
        "    print(f\"ğŸ“š Corpus: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus, vocab = generate_rich_corpus()\n",
        "\n",
        "# ===============================================================\n",
        "# 4. TOPOLOGICAL NEURAL NETWORK (with E/C normalization fix)\n",
        "# ===============================================================\n",
        "class TopologicalNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=256, hidden_dim=512, output_dim=256, lambda_topo=1.0):\n",
        "        super().__init__()\n",
        "        self.lambda_topo = lambda_topo\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.energy = self.coupling = self.stability = 0.0\n",
        "        self.energy_ratio = 1.0\n",
        "\n",
        "    def compute_topological_terms(self, activations):\n",
        "        eps = 1e-8\n",
        "        E = torch.mean(activations ** 2)\n",
        "        grad = torch.autograd.grad(E, activations, retain_graph=True, create_graph=True, allow_unused=True)\n",
        "        if grad[0] is None:\n",
        "            C = E\n",
        "        else:\n",
        "            C_raw = torch.mean(grad[0] ** 2)\n",
        "            N = activations.numel()\n",
        "            scale = 4.0 / (N ** 2)\n",
        "            C = C_raw / (scale + eps)\n",
        "        ratio = E / (C + eps)\n",
        "        ratio_clamped = torch.clamp(ratio, 0.25, 4.0)\n",
        "        E_d, C_d, S_d = E.detach(), C.detach(), torch.abs(ratio - 1.0).detach()\n",
        "        return E_d, C_d, S_d, ratio_clamped\n",
        "\n",
        "    def forward(self, x):\n",
        "        reshaped = False\n",
        "        if len(x.shape) == 3:\n",
        "            b, s, d = x.shape\n",
        "            x = x.reshape(b * s, d)\n",
        "            reshaped = True\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        h2_norm = self.layer_norm(h2)\n",
        "        out = self.fc3(h2_norm)\n",
        "        if self.training:\n",
        "            E_d, C_d, S_d, ratio_for_ctrl = self.compute_topological_terms(h2_norm)\n",
        "            self.energy, self.coupling, self.stability = E_d.item(), C_d.item(), S_d.item()\n",
        "            if not hasattr(self, \"_ratio_ema\"):\n",
        "                self._ratio_ema = ratio_for_ctrl.detach()\n",
        "            self._ratio_ema = 0.9 * self._ratio_ema + 0.1 * ratio_for_ctrl.detach()\n",
        "            correction = self.lambda_topo * torch.log(self._ratio_ema + 1e-8)\n",
        "            out = out + correction * torch.tanh(out)\n",
        "        if reshaped:\n",
        "            out = out.reshape(b, s, -1)\n",
        "        return out\n",
        "\n",
        "# ===============================================================\n",
        "# 5. COMPLETE RDT MODEL\n",
        "# ===============================================================\n",
        "class RDTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab, emb_dim=256, hidden_dim=512, alpha=1.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
        "        self.vocab_size = len(vocab)\n",
        "        self.rdt_index = RDTEmbeddingIndex(self.vocab_size, emb_dim, alpha)\n",
        "        self.embed = nn.Embedding(self.vocab_size, emb_dim)\n",
        "        self.tnn = TopologicalNeuralNetwork(\n",
        "            input_dim=emb_dim, hidden_dim=hidden_dim, output_dim=emb_dim, lambda_topo=1.0)\n",
        "        self.fc_out = nn.Linear(emb_dim, self.vocab_size)\n",
        "        print(f\"\\nğŸ“Š Complete Model:\")\n",
        "        print(f\"   Parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
        "        print(f\"   Components: RDT Index + TNN (MHD) + Spatial Search\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        e = self.embed(x)\n",
        "        h = self.tnn(e)\n",
        "        out = self.fc_out(h)\n",
        "        return out, h\n",
        "\n",
        "    def compute_rdt_spatial_loss(self, predictions, targets, hidden_states):\n",
        "        batch_size, seq_len, vocab_size = predictions.shape\n",
        "        pred_words = torch.argmax(predictions, dim=-1).view(-1)\n",
        "        target_words = targets.view(-1)\n",
        "        with torch.no_grad():\n",
        "            embeddings_dict = {idx: self.embed.weight[idx] for idx in range(self.vocab_size)}\n",
        "        total_bonus, n_valid = 0.0, 0\n",
        "        sample_size = min(100, len(pred_words))\n",
        "        indices = random.sample(range(len(pred_words)), sample_size)\n",
        "        for i in indices:\n",
        "            pred_idx = pred_words[i].item()\n",
        "            target_idx = target_words[i].item()\n",
        "            if target_idx == 0: continue\n",
        "            hidden = hidden_states.view(-1, hidden_states.size(-1))[i]\n",
        "            pred_depth = self.rdt_index.word_depth[pred_idx]\n",
        "            target_depth = self.rdt_index.word_depth[target_idx]\n",
        "            if pred_depth == target_depth:\n",
        "                depth_bonus = 1.0\n",
        "            else:\n",
        "                min_depth = min(pred_depth, target_depth) + 1\n",
        "                max_depth = max(pred_depth, target_depth) + 1\n",
        "                depth_ratio = min_depth / max_depth\n",
        "                depth_bonus = depth_ratio\n",
        "            candidates = self.rdt_index.hierarchical_search(hidden, target_idx, embeddings_dict, k=10)\n",
        "            if pred_idx in candidates:\n",
        "                rank = candidates.index(pred_idx)\n",
        "                rank_bonus = 1.0 / (rank + 1)\n",
        "                combined_bonus = depth_bonus * rank_bonus\n",
        "                total_bonus += combined_bonus\n",
        "            else:\n",
        "                total_bonus += depth_bonus * 0.1\n",
        "            n_valid += 1\n",
        "        return total_bonus / n_valid if n_valid > 0 else 0.0\n",
        "\n",
        "# ===============================================================\n",
        "# 6. TRAINING\n",
        "# ===============================================================\n",
        "def prepare_batch(sentences, word2idx, maxlen=15):\n",
        "    batch_x, batch_y = [], []\n",
        "    for sent in sentences:\n",
        "        if len(sent) < 2: continue\n",
        "        idxs = [word2idx.get(w, 0) for w in sent]\n",
        "        if len(idxs) < 2: continue\n",
        "        x, y = idxs[:-1], idxs[1:]\n",
        "        if len(x) < maxlen:\n",
        "            x = x + [0]*(maxlen-len(x)); y = y + [0]*(maxlen-len(y))\n",
        "        else:\n",
        "            x, y = x[:maxlen], y[:maxlen]\n",
        "        batch_x.append(x); batch_y.append(y)\n",
        "    if not batch_x: return None, None\n",
        "    return torch.tensor(batch_x, device=device), torch.tensor(batch_y, device=device)\n",
        "\n",
        "def train_model(model, corpus, epochs=50, initial_lr=1e-3, batch_size=64):\n",
        "    optimizer = TopologicalAdam(model.parameters(), lr=initial_lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "    loss_log, spatial_log, energy_log, coupling_log, ratio_log, topo_energy_log = [], [], [], [], [], []\n",
        "    print(f\"\\nğŸ”¥ Training COMPLETE SYSTEM WITH MHD INSIGHTS:\")\n",
        "    print(f\"   âœ“ RDT spatial index\\n   âœ“ Topological Neural Network (MHD)\\n   âœ“ Topological Adam optimizer\\n   âœ“ Hierarchical search\\n   âœ“ MHD-inspired loss function\\n\")\n",
        "    best_loss = float('inf')\n",
        "    for ep in range(1, epochs+1):\n",
        "        random.shuffle(corpus)\n",
        "        epoch_loss = epoch_spatial = epoch_tnn_energy = epoch_tnn_coupling = epoch_ratio = 0.0\n",
        "        n_batches = 0\n",
        "        for i in range(0, len(corpus), batch_size):\n",
        "            batch = corpus[i:i+batch_size]\n",
        "            x, y = prepare_batch(batch, model.word2idx)\n",
        "            if x is None: continue\n",
        "            out, hidden = model(x)\n",
        "            loss = criterion(out.view(-1, model.vocab_size), y.view(-1))\n",
        "            spatial_bonus = model.compute_rdt_spatial_loss(out, y, hidden)\n",
        "            spatial_weight = 0.5\n",
        "            total_loss = loss - (spatial_weight * spatial_bonus)\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_spatial += spatial_bonus\n",
        "            epoch_tnn_energy += model.tnn.energy\n",
        "            epoch_tnn_coupling += model.tnn.coupling\n",
        "            epoch_ratio += model.tnn.energy_ratio\n",
        "            n_batches += 1\n",
        "        if n_batches:\n",
        "            mean_loss = epoch_loss / n_batches\n",
        "            mean_spatial = epoch_spatial / n_batches\n",
        "            mean_tnn_energy = epoch_tnn_energy / n_batches\n",
        "            mean_tnn_coupling = epoch_tnn_coupling / n_batches\n",
        "            mean_ratio = epoch_ratio / n_batches\n",
        "            mean_topo_energy = optimizer.energy()\n",
        "            loss_log.append(mean_loss); spatial_log.append(mean_spatial)\n",
        "            energy_log.append(mean_tnn_energy); coupling_log.append(mean_tnn_coupling)\n",
        "            ratio_log.append(mean_ratio); topo_energy_log.append(mean_topo_energy)\n",
        "            scheduler.step(mean_loss)\n",
        "            marker = \"ğŸ”¥\" if mean_loss < best_loss else \"\"\n",
        "            best_loss = min(best_loss, mean_loss)\n",
        "            if ep % 5 == 0 or ep == 1:\n",
        "                print(f\"Epoch {ep:2d}: loss={mean_loss:.4f} | spatial={mean_spatial:.4f} | E/C_ratio={mean_ratio:.3f} | TNN_E={mean_tnn_energy:.2e} | Adam_E={mean_topo_energy:.2e} {marker}\")\n",
        "    print(f\"\\nâœ… Training Complete! Best loss: {best_loss:.4f}\")\n",
        "    return loss_log, spatial_log, energy_log, coupling_log, ratio_log, topo_energy_log\n",
        "\n",
        "# ===============================================================\n",
        "# 7. TEXT GENERATION\n",
        "# ===============================================================\n",
        "def generate_text(model, start_text, max_len=15, temperature=0.8):\n",
        "    model.eval(); words = start_text.lower().split()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            x = torch.tensor([[model.word2idx.get(w, 0) for w in words]], device=device)\n",
        "            out, _ = model(x)\n",
        "            logits = out[0, -1, :] / temperature\n",
        "            probs = F.softmax(logits, dim=0)\n",
        "            next_idx = torch.multinomial(probs, 1).item()\n",
        "            if next_idx == 0: break\n",
        "            words.append(model.idx2word[next_idx])\n",
        "            if len(words) > 20: break\n",
        "    return ' '.join(words)\n",
        "\n",
        "# ===============================================================\n",
        "# 8. RUN COMPLETE SYSTEM\n",
        "# ===============================================================\n",
        "print(\"=\"*70)\n",
        "print(\"COMPLETE SYSTEM: RDT + TNN (MHD) + TOPOLOGICAL ADAM + SPATIAL INDEX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = RDTLanguageModel(vocab, emb_dim=256, hidden_dim=512, alpha=1.5).to(device)\n",
        "losses, spatials, energies, couplings, ratios, adam_energies = train_model(model, corpus, epochs=50, initial_lr=1e-3, batch_size=64)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEXT GENERATION\")\n",
        "print(\"=\"*70)\n",
        "for prompt in [\"the man"
      ],
      "metadata": {
        "id": "QSlBNH-EzOA1",
        "outputId": "07ae92fe-af03-4d29-dafb-96462de5a896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 337) (ipython-input-3959432459.py, line 337)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3959432459.py\"\u001b[0;36m, line \u001b[0;32m337\u001b[0m\n\u001b[0;31m    for prompt in [\"the man\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 337)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  COMPLETE RDT LANGUAGE MODEL\n",
        "#  ALL COMPONENTS: RDT + TNN + Topological Adam + Spatial Index + MHD Insights\n",
        "#  (with corrected E/C normalization inside TNN)\n",
        "# ===============================================================\n",
        "!pip install topological-adam --quiet\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np, math, random\n",
        "from collections import defaultdict\n",
        "from topological_adam import TopologicalAdam\n",
        "from matplotlib import pyplot as plt\n",
        "from numba import njit\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Device: {device}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 1. YOUR RDT MATH (unchanged)\n",
        "# ===============================================================\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    \"\"\"YOUR RDT depth formula\"\"\"\n",
        "    if n < 2: return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d: break\n",
        "        x //= d\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def rdt_grid_size(n, alpha=1.5):\n",
        "    \"\"\"YOUR adaptive grid sizing from spatial index\"\"\"\n",
        "    if n <= 1:\n",
        "        return 2\n",
        "    d = max(2, int(np.log(n + 1) ** alpha))\n",
        "    return min(d, 32)\n",
        "\n",
        "# ===============================================================\n",
        "# 2. YOUR RDT SPATIAL INDEX (unchanged)\n",
        "# ===============================================================\n",
        "class RDTEmbeddingIndex:\n",
        "    \"\"\"\n",
        "    YOUR spatial index structure adapted to embedding space\n",
        "    Uses YOUR hierarchical search and adaptive grid sizing\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, alpha=1.5):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Build shell structure using YOUR formula\n",
        "        self.shells = defaultdict(list)\n",
        "        self.word_depth = {}\n",
        "        for idx in range(vocab_size):\n",
        "            depth = rdt_depth(idx, alpha)\n",
        "            self.shells[depth].append(idx)\n",
        "            self.word_depth[idx] = depth\n",
        "\n",
        "        # YOUR adaptive grid sizes per shell\n",
        "        self.shell_grid_sizes = {}\n",
        "        for depth, words in self.shells.items():\n",
        "            n = len(words)\n",
        "            self.shell_grid_sizes[depth] = rdt_grid_size(n, alpha)\n",
        "\n",
        "        print(f\"\\nğŸ”¬ RDT Spatial Index:\")\n",
        "        for depth in sorted(self.shells.keys()):\n",
        "            n = len(self.shells[depth])\n",
        "            g = self.shell_grid_sizes[depth]\n",
        "            print(f\"   Shell {depth}: {n} words, grid {g}Ã—{g}\")\n",
        "\n",
        "    def find_nearest_in_shell(self, embedding, target_shell, embeddings_dict, k=5):\n",
        "        \"\"\"YOUR spatial search within a shell\"\"\"\n",
        "        if target_shell not in self.shells:\n",
        "            return []\n",
        "        candidates = self.shells[target_shell]\n",
        "        distances = []\n",
        "        for word_idx in candidates:\n",
        "            emb = embeddings_dict[word_idx]\n",
        "            sim = F.cosine_similarity(embedding.unsqueeze(0), emb.unsqueeze(0))\n",
        "            distances.append((word_idx, sim.item()))\n",
        "        distances.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [idx for idx, _ in distances[:k]]\n",
        "\n",
        "    def hierarchical_search(self, embedding, current_word_idx, embeddings_dict, k=10):\n",
        "        \"\"\"YOUR hierarchical traversal strategy\"\"\"\n",
        "        current_shell = self.word_depth.get(current_word_idx, 0)\n",
        "\n",
        "        # Search current shell first\n",
        "        candidates = self.find_nearest_in_shell(\n",
        "            embedding, current_shell, embeddings_dict, k=k\n",
        "        )\n",
        "\n",
        "        # Expand to nearby shells if needed (YOUR expansion strategy)\n",
        "        if len(candidates) < k:\n",
        "            for offset in [1, -1, 2, -2]:\n",
        "                nearby_shell = current_shell + offset\n",
        "                if nearby_shell in self.shells:\n",
        "                    more = self.find_nearest_in_shell(\n",
        "                        embedding, nearby_shell, embeddings_dict, k=k-len(candidates)\n",
        "                    )\n",
        "                    candidates.extend(more)\n",
        "                    if len(candidates) >= k:\n",
        "                        break\n",
        "        return candidates[:k]\n",
        "\n",
        "# ===============================================================\n",
        "# 3. DATA (unchanged)\n",
        "# ===============================================================\n",
        "def generate_rich_corpus():\n",
        "    subjects = [\n",
        "        'the man', 'the woman', 'the child', 'the king', 'the queen',\n",
        "        'the soldier', 'the merchant', 'the teacher', 'the old man',\n",
        "        'the young woman', 'a stranger', 'the traveler', 'the farmer',\n",
        "        'the priest', 'the warrior', 'the beggar', 'the noble'\n",
        "    ]\n",
        "    verbs = [\n",
        "        'walked', 'ran', 'went', 'came', 'spoke', 'thought', 'found',\n",
        "        'discovered', 'remembered', 'believed', 'understood', 'left',\n",
        "        'arrived', 'departed', 'searched', 'wondered', 'feared', 'hoped',\n",
        "        'carried', 'held', 'took', 'gave', 'brought', 'sent'\n",
        "    ]\n",
        "    locations = [\n",
        "        'to the house', 'to the market', 'to the river', 'to the forest',\n",
        "        'to the castle', 'through the valley', 'across the land',\n",
        "        'to the mountain', 'to the sea', 'to the village', 'to the city',\n",
        "        'through the door', 'into the darkness', 'toward the light',\n",
        "        'beyond the horizon', 'near the gate'\n",
        "    ]\n",
        "    adjectives = [\n",
        "        'happy', 'sad', 'brave', 'wise', 'afraid', 'calm', 'strong',\n",
        "        'gentle', 'proud', 'humble', 'kind', 'cruel', 'young', 'old',\n",
        "        'rich', 'poor', 'noble', 'simple', 'great', 'small'\n",
        "    ]\n",
        "    times = [\n",
        "        'in the morning', 'at night', 'at dawn', 'at dusk', 'yesterday',\n",
        "        'long ago', 'one day', 'when winter came', 'when spring arrived',\n",
        "        'at midnight', 'before sunrise', 'after sunset'\n",
        "    ]\n",
        "    objects = [\n",
        "        'a sword', 'a book', 'a letter', 'a key', 'a treasure', 'a secret',\n",
        "        'a truth', 'a dream', 'a memory', 'a promise', 'a gift'\n",
        "    ]\n",
        "\n",
        "    corpus = []\n",
        "    for _ in range(4000):\n",
        "        s, v, l = random.choice(subjects), random.choice(verbs), random.choice(locations)\n",
        "        corpus.append(f\"{s} {v} {l}\".split())\n",
        "    for _ in range(3000):\n",
        "        s, adj = random.choice(subjects), random.choice(adjectives)\n",
        "        corpus.append(f\"{s} was {adj}\".split())\n",
        "    for _ in range(3000):\n",
        "        t, s, v = random.choice(times), random.choice(subjects), random.choice(verbs)\n",
        "        corpus.append(f\"{t} {s} {v}\".split())\n",
        "    for _ in range(2000):\n",
        "        s = random.choice(subjects)\n",
        "        v = random.choice(['found', 'held', 'carried', 'brought', 'took'])\n",
        "        o = random.choice(objects)\n",
        "        corpus.append(f\"{s} {v} {o}\".split())\n",
        "    for _ in range(2000):\n",
        "        s1, adj1 = random.choice(subjects), random.choice(adjectives)\n",
        "        s2, adj2 = random.choice(['he', 'she', 'they']), random.choice(adjectives)\n",
        "        corpus.append(f\"{s1} was {adj1} and {s2} was {adj2}\".split())\n",
        "    for _ in range(2000):\n",
        "        s, adj = random.choice(['the', 'a']), random.choice(adjectives)\n",
        "        noun = random.choice(['man', 'woman', 'child', 'king', 'soldier'])\n",
        "        v = random.choice(verbs)\n",
        "        corpus.append(f\"{s} {adj} {noun} {v}\".split())\n",
        "\n",
        "    random.shuffle(corpus)\n",
        "    vocab = sorted(set(word for sent in corpus for word in sent))\n",
        "    print(f\"ğŸ“š Corpus: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus, vocab = generate_rich_corpus()\n",
        "\n",
        "# ===============================================================\n",
        "# 4. YOUR TOPOLOGICAL NEURAL NETWORK (MHD + normalization fix)\n",
        "# ===============================================================\n",
        "class TopologicalNeuralNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    YOUR TNN with MHD closure insights:\n",
        "    - Uses RATIOS not differences (S_Î± = Î·Â·u/c)\n",
        "    - Energy and coupling interact through division\n",
        "    - Proper normalization like shared coordinate 'c'\n",
        "    - E/C normalization fix to avoid scale blowup\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=256, hidden_dim=512, output_dim=256, lambda_topo=1.0):\n",
        "        super().__init__()\n",
        "        self.lambda_topo = lambda_topo\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.energy = 0.0\n",
        "        self.coupling = 0.0\n",
        "        self.stability = 0.0\n",
        "        self.energy_ratio = 1.0\n",
        "\n",
        "    def compute_topological_terms(self, activations):\n",
        "        \"\"\"\n",
        "        E = mean(h^2)\n",
        "        dE/dh = (2/N) * h â†’ mean((dE/dh)^2) = (4/N^2) * mean(h^2) = (4/N^2)*E\n",
        "        Normalize C so C â‰ˆ E in ideal equilibrium.\n",
        "        \"\"\"\n",
        "        eps = 1e-8\n",
        "        E = torch.mean(activations ** 2)\n",
        "\n",
        "        grad = torch.autograd.grad(E, activations, retain_graph=True,\n",
        "                                   create_graph=True, allow_unused=True)\n",
        "        if grad[0] is None:\n",
        "            C = E\n",
        "        else:\n",
        "            C_raw = torch.mean(grad[0] ** 2)\n",
        "            N = activations.numel()\n",
        "            # C_raw = (4/N^2) * E  â‡’  C = C_raw / (4/N^2) = C_raw * (N^2/4)\n",
        "            scale = 4.0 / (N ** 2)\n",
        "            C = C_raw / (scale + eps)\n",
        "\n",
        "        ratio = E / (C + eps)\n",
        "        ratio_clamped = torch.clamp(ratio, 0.25, 4.0)\n",
        "\n",
        "        E_d = E.detach()\n",
        "        C_d = C.detach()\n",
        "        S_d = torch.abs(ratio - 1.0).detach()\n",
        "        return E_d, C_d, S_d, ratio_clamped\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Handle 3D input (batch, seq, dim)\n",
        "        reshaped = False\n",
        "        if len(x.shape) == 3:\n",
        "            b, s, d = x.shape\n",
        "            x = x.reshape(b * s, d)\n",
        "            reshaped = True\n",
        "\n",
        "        # Forward pass through layers\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        h2 = F.relu(self.fc2(h1))\n",
        "        h2_norm = self.layer_norm(h2)\n",
        "        out = self.fc3(h2_norm)\n",
        "\n",
        "        # MHD-inspired correction using normalized ratio\n",
        "        if self.training:\n",
        "            E_d, C_d, S_d, ratio_for_ctrl = self.compute_topological_terms(h2_norm)\n",
        "            self.energy, self.coupling, self.stability = E_d.item(), C_d.item(), S_d.item()\n",
        "\n",
        "            # Smooth controller with EMA\n",
        "            if not hasattr(self, \"_ratio_ema\"):\n",
        "                self._ratio_ema = ratio_for_ctrl.detach()\n",
        "            self._ratio_ema = 0.9 * self._ratio_ema + 0.1 * ratio_for_ctrl.detach()\n",
        "\n",
        "            correction = self.lambda_topo * torch.log(self._ratio_ema + 1e-8)\n",
        "            out = out + correction * torch.tanh(out)\n",
        "\n",
        "            # For external logs, expose the unclamped ratio value (safe)\n",
        "            self.energy_ratio = float((E_d / (C_d + 1e-8)).cpu())\n",
        "\n",
        "        if reshaped:\n",
        "            out = out.reshape(b, s, -1)\n",
        "        return out\n",
        "\n",
        "# ===============================================================\n",
        "# 5. COMPLETE RDT MODEL (spatial loss with MHD insights)\n",
        "# ===============================================================\n",
        "class RDTLanguageModel(nn.Module):\n",
        "    \"\"\"\n",
        "    COMPLETE MODEL WITH ALL YOUR COMPONENTS + MHD INSIGHTS:\n",
        "    1. RDT shell structure\n",
        "    2. YOUR Topological Neural Network (with MHD ratio correction)\n",
        "    3. YOUR spatial index for embeddings\n",
        "    4. Trained with YOUR Topological Adam\n",
        "    5. MHD-inspired spatial loss (uses depth ratios)\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab, emb_dim=256, hidden_dim=512, alpha=1.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.word2idx = {w:i for i,w in enumerate(vocab)}\n",
        "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
        "        self.vocab_size = len(vocab)\n",
        "\n",
        "        # COMPONENT 1: YOUR RDT SPATIAL INDEX\n",
        "        self.rdt_index = RDTEmbeddingIndex(self.vocab_size, emb_dim, alpha)\n",
        "\n",
        "        # COMPONENT 2: Embeddings\n",
        "        self.embed = nn.Embedding(self.vocab_size, emb_dim)\n",
        "\n",
        "        # COMPONENT 3: YOUR TOPOLOGICAL NEURAL NETWORK (with MHD)\n",
        "        self.tnn = TopologicalNeuralNetwork(\n",
        "            input_dim=emb_dim, hidden_dim=hidden_dim, output_dim=emb_dim, lambda_topo=1.0\n",
        "        )\n",
        "\n",
        "        # COMPONENT 4: Output layer\n",
        "        self.fc_out = nn.Linear(emb_dim, self.vocab_size)\n",
        "\n",
        "        print(f\"\\nğŸ“Š Complete Model:\")\n",
        "        print(f\"   Parameters: {sum(p.numel() for p in self.parameters()):,}\")\n",
        "        print(f\"   Components: RDT Index + TNN (MHD) + Spatial Search\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len)\n",
        "        e = self.embed(x)                # Embeddings\n",
        "        h = self.tnn(e)                  # YOUR TNN with MHD correction\n",
        "        out = self.fc_out(h)             # Output logits\n",
        "        return out, h                    # Return hidden states for spatial loss\n",
        "\n",
        "    def compute_rdt_spatial_loss(self, predictions, targets, hidden_states):\n",
        "        \"\"\"\n",
        "        YOUR SPATIAL INDEX LOSS WITH MHD INSIGHTS:\n",
        "        Uses RATIOS (like S_Î± = Î·Â·u/c) instead of products:\n",
        "        - Shell depth ratio (like coordinate ratio in MHD)\n",
        "        - Hierarchical search with proper scaling\n",
        "        - Rewards structural similarity\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, vocab_size = predictions.shape\n",
        "        pred_words = torch.argmax(predictions, dim=-1).view(-1)\n",
        "        target_words = targets.view(-1)\n",
        "\n",
        "        # Build embeddings dict for spatial search\n",
        "        with torch.no_grad():\n",
        "            embeddings_dict = {idx: self.embed.weight[idx] for idx in range(self.vocab_size)}\n",
        "\n",
        "        total_bonus, n_valid = 0.0, 0\n",
        "\n",
        "        # Sample for efficiency\n",
        "        sample_size = min(100, len(pred_words))\n",
        "        indices = random.sample(range(len(pred_words)), sample_size)\n",
        "\n",
        "        for i in indices:\n",
        "            pred_idx = pred_words[i].item()\n",
        "            target_idx = target_words[i].item()\n",
        "            if target_idx == 0:  # Skip padding\n",
        "                continue\n",
        "\n",
        "            hidden = hidden_states.view(-1, hidden_states.size(-1))[i]\n",
        "\n",
        "            # Depth ratio bonus\n",
        "            pred_depth = self.rdt_index.word_depth[pred_idx]\n",
        "            target_depth = self.rdt_index.word_depth[target_idx]\n",
        "            if pred_depth == target_depth:\n",
        "                depth_bonus = 1.0\n",
        "            else:\n",
        "                min_depth = min(pred_depth, target_depth) + 1\n",
        "                max_depth = max(pred_depth, target_depth) + 1\n",
        "                depth_bonus = min_depth / max_depth  # ratio in (0,1]\n",
        "\n",
        "            # Hierarchical spatial candidate check\n",
        "            candidates = self.rdt_index.hierarchical_search(\n",
        "                hidden, target_idx, embeddings_dict, k=10\n",
        "            )\n",
        "            if pred_idx in candidates:\n",
        "                rank = candidates.index(pred_idx)\n",
        "                rank_bonus = 1.0 / (rank + 1)\n",
        "                combined_bonus = depth_bonus * rank_bonus\n",
        "                total_bonus += combined_bonus\n",
        "            else:\n",
        "                total_bonus += depth_bonus * 0.1\n",
        "\n",
        "            n_valid += 1\n",
        "\n",
        "        return total_bonus / n_valid if n_valid > 0 else 0.0\n",
        "\n",
        "# ===============================================================\n",
        "# 6. TRAINING WITH YOUR TOPOLOGICAL ADAM\n",
        "# ===============================================================\n",
        "def prepare_batch(sentences, word2idx, maxlen=15):\n",
        "    batch_x, batch_y = [], []\n",
        "    for sent in sentences:\n",
        "        if len(sent) < 2: continue\n",
        "        idxs = [word2idx.get(w, 0) for w in sent]\n",
        "        if len(idxs) < 2: continue\n",
        "        x, y = idxs[:-1], idxs[1:]\n",
        "        if len(x) < maxlen:\n",
        "            x = x + [0] * (maxlen - len(x))\n",
        "            y = y + [0] * (maxlen - len(y))\n",
        "        else:\n",
        "            x, y = x[:maxlen], y[:maxlen]\n",
        "        batch_x.append(x)\n",
        "        batch_y.append(y)\n",
        "    if not batch_x:\n",
        "        return None, None\n",
        "    return torch.tensor(batch_x, device=device), torch.tensor(batch_y, device=device)\n",
        "\n",
        "def train_model(model, corpus, epochs=50, initial_lr=1e-3, batch_size=64):\n",
        "    optimizer = TopologicalAdam(model.parameters(), lr=initial_lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.5, patience=5\n",
        "    )\n",
        "\n",
        "    loss_log, spatial_log, energy_log, coupling_log, ratio_log, topo_energy_log = [], [], [], [], [], []\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    print(f\"\\nğŸ”¥ Training COMPLETE SYSTEM WITH MHD INSIGHTS:\")\n",
        "    print(f\"   âœ“ RDT spatial index\")\n",
        "    print(f\"   âœ“ Topological Neural Network (MHD ratio correction)\")\n",
        "    print(f\"   âœ“ Topological Adam optimizer\")\n",
        "    print(f\"   âœ“ Hierarchical search with depth ratios\")\n",
        "    print(f\"   âœ“ MHD-inspired loss function\\n\")\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        random.shuffle(corpus)\n",
        "        epoch_loss = epoch_spatial = epoch_tnn_energy = epoch_tnn_coupling = epoch_ratio = 0.0\n",
        "        n_batches = 0\n",
        "\n",
        "        for i in range(0, len(corpus), batch_size):\n",
        "            batch = corpus[i:i+batch_size]\n",
        "            x, y = prepare_batch(batch, model.word2idx)\n",
        "            if x is None: continue\n",
        "\n",
        "            # Forward pass through COMPLETE system\n",
        "            out, hidden = model(x)  # Embed â†’ TNN (MHD) â†’ Output\n",
        "\n",
        "            # CE loss\n",
        "            loss = criterion(out.view(-1, model.vocab_size), y.view(-1))\n",
        "\n",
        "            # Spatial bonus\n",
        "            spatial_bonus = model.compute_rdt_spatial_loss(out, y, hidden)\n",
        "\n",
        "            # Combined objective (subtract bonus)\n",
        "            spatial_weight = 0.5\n",
        "            total_loss = loss - (spatial_weight * spatial_bonus)\n",
        "\n",
        "            # Backprop with Topological Adam\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_spatial += spatial_bonus\n",
        "            epoch_tnn_energy += model.tnn.energy\n",
        "            epoch_tnn_coupling += model.tnn.coupling\n",
        "            epoch_ratio += model.tnn.energy_ratio\n",
        "            n_batches += 1\n",
        "\n",
        "        if n_batches:\n",
        "            mean_loss = epoch_loss / n_batches\n",
        "            mean_spatial = epoch_spatial / n_batches\n",
        "            mean_tnn_energy = epoch_tnn_energy / n_batches\n",
        "            mean_tnn_coupling = epoch_tnn_coupling / n_batches\n",
        "            mean_ratio = epoch_ratio / n_batches\n",
        "            mean_topo_energy = optimizer.energy()\n",
        "\n",
        "            loss_log.append(mean_loss)\n",
        "            spatial_log.append(mean_spatial)\n",
        "            energy_log.append(mean_tnn_energy)\n",
        "            coupling_log.append(mean_tnn_coupling)\n",
        "            ratio_log.append(mean_ratio)\n",
        "            topo_energy_log.append(mean_topo_energy)\n",
        "\n",
        "            scheduler.step(mean_loss)\n",
        "            improved = mean_loss < best_loss\n",
        "            if improved: best_loss = mean_loss\n",
        "            if ep % 5 == 0 or ep == 1:\n",
        "                print(f\"Epoch {ep:2d}: loss={mean_loss:.4f} | spatial={mean_spatial:.4f} | \"\n",
        "                      f\"E/C_ratio={mean_ratio:.3f} | TNN_E={mean_tnn_energy:.2e} | \"\n",
        "                      f\"Adam_E={mean_topo_energy:.2e} {'ğŸ”¥' if improved else ''}\")\n",
        "\n",
        "    print(f\"\\nâœ… Training Complete!\")\n",
        "    print(f\"   Best loss: {best_loss:.4f}\")\n",
        "    print(f\"   Final spatial bonus: {spatial_log[-1]:.4f}\")\n",
        "    print(f\"   Final E/C ratio: {ratio_log[-1]:.3f}\")\n",
        "\n",
        "    return loss_log, spatial_log, energy_log, coupling_log, ratio_log, topo_energy_log\n",
        "# ===============================================================\n",
        "# 8. RUN COMPLETE SYSTEM\n",
        "# ===============================================================\n",
        "print(\"=\"*70)\n",
        "print(\"COMPLETE SYSTEM: RDT + TNN (MHD) + TOPOLOGICAL ADAM + SPATIAL INDEX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = RDTLanguageModel(vocab, emb_dim=256, hidden_dim=512, alpha=1.5).to(device)\n",
        "\n",
        "losses, spatials, energies, couplings, ratios, adam_energies = train_model(\n",
        "    model, corpus, epochs=50, initial_lr=1e-3, batch_size=64\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEXT GENERATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for prompt in [\"the man\", \"in the morning\", \"she was\", \"long ago\"]:\n",
        "    print(f\"\\n'{prompt}':\")\n",
        "    for i in range(3):\n",
        "        print(f\"  {generate_text(model, prompt, max_len=12)}\")\n",
        "# ===============================================================\n",
        "# 7. GENERATION\n",
        "# ===============================================================\n",
        "def generate_text(model, start_text, max_len=15, temperature=0.8):\n",
        "    model.eval()\n",
        "    words = start_text.lower().split()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            x = torch.tensor([[model.word2idx.get(w, 0) for w in words]], device=device)\n",
        "            out, _ = model(x)\n",
        "            logits = out[0, -1, :] / temperature\n",
        "            probs = F.softmax(logits, dim=0)\n",
        "            next_idx = torch.multinomial(probs, 1).item()\n",
        "            if next_idx == 0: break\n",
        "            words.append(model.idx2word[next_idx])\n",
        "            if len(words) > 20: break\n",
        "    return ' '.join(words)\n",
        "\n",
        "# ===============================================================\n",
        "# 8. RUN COMPLETE SYSTEM\n",
        "# ===============================================================\n",
        "print(\"=\"*70)\n",
        "print(\"COMPLETE SYSTEM: RDT + TNN (MHD) + TOPOLOGICAL ADAM + SPATIAL INDEX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = RDTLanguageModel(vocab, emb_dim=256, hidden_dim=512, alpha=1.5).to(device)\n",
        "\n",
        "losses, spatials, energies, couplings, ratios, adam_energies = train_model(\n",
        "    model, corpus, epochs=50, initial_lr=1e-3, batch_size=64\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEXT GENERATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for prompt in [\"the man\", \"in the morning\", \""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "8cLwRZWB1Py4",
        "outputId": "5ffc19a8-5c4e-40a5-ef99-73f578474d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 524) (ipython-input-3873109890.py, line 524)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3873109890.py\"\u001b[0;36m, line \u001b[0;32m524\u001b[0m\n\u001b[0;31m    for prompt in [\"the man\", \"in the morning\", \"\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 524)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  FIX PYTORCH / CUDA CONFLICT (COLAB SAFE)\n",
        "# ===============================================================\n",
        "\n",
        "# 1ï¸âƒ£ Remove every preloaded Torch build\n",
        "!pip uninstall -y torch torchvision torchaudio torchtext torchdata torchsummary\n",
        "\n",
        "# 2ï¸âƒ£ Fresh unified install (CUDA 12.6 build)\n",
        "!pip install torch==2.8.0+cu126 torchvision==0.23.0+cu126 torchaudio==2.8.0+cu126 --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install topological-adam --quiet\n",
        "\n",
        "# 3ï¸âƒ£ Verify everything before loading your model\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from topological_adam import TopologicalAdam\n",
        "print(f\"ğŸš€ Torch version: {torch.__version__}\")\n",
        "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L8lVOxYx6nfZ",
        "outputId": "a609f01f-8f55-4bf6-b158-2d92f14da5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchdata as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchsummary as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Collecting torch==2.8.0+cu126\n",
            "  Using cached https://download.pytorch.org/whl/cu126/torch-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision==0.23.0+cu126\n",
            "  Using cached https://download.pytorch.org/whl/cu126/torchvision-0.23.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio==2.8.0+cu126\n",
            "  Using cached https://download.pytorch.org/whl/cu126/torchaudio-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0+cu126) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0+cu126) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0+cu126) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0+cu126) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0+cu126) (3.0.3)\n",
            "Using cached https://download.pytorch.org/whl/cu126/torch-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl (821.8 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu126/torchvision-0.23.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu126/torchaudio-2.8.0%2Bcu126-cp312-cp312-manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/requirements.py\", line 43, in __init__\n",
            "    self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 718, in __init__\n",
            "    self._specs = frozenset(map(Specifier, split_specifiers))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 331, in __hash__\n",
            "    return hash(self._canonical_spec)\n",
            "                ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 324, in _canonical_spec\n",
            "    canonical_version = canonicalize_version(\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/utils.py\", line 66, in canonicalize_version\n",
            "    parsed = Version(version)\n",
            "             ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/version.py\", line 205, in __init__\n",
            "    self._version = _Version(\n",
            "                    ^^^^^^^^^\n",
            "  File \"<string>\", line 1, in <lambda>\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n",
            "    style = Style(color=\"red\")\n",
            "            ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n",
            "    def _make_color(color: Union[Color, str]) -> Color:\n",
            "                           ~~~~~^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 395, in inner\n",
            "    return _caches[func](*args, **kwds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/typing.py\", line 515, in __getitem__\n",
            "    @_tp_cache\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PosixPath' object has no attribute '_str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2761284483.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 2ï¸âƒ£ Fresh unified install (CUDA 12.6 build)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torch==2.8.0+cu126 torchvision==0.23.0+cu126 torchaudio==2.8.0+cu126 --index-url https://download.pytorch.org/whl/cu126'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install topological-adam --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 3ï¸âƒ£ Verify everything before loading your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__fspath__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             self._str = self._format_parsed_parts(self.drive, self.root,\n\u001b[0m\u001b[1;32m    444\u001b[0m                                                   self._tail) or '.'\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mroot\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;34m\"\"\"The root of the path, if any.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ===============================================================\n",
        "#  COMPLETE RDT LANGUAGE MODEL - FIXED IMPORT ORDER\n",
        "# ===============================================================\n",
        "\n",
        "# 1ï¸âƒ£  Restart-safe reinstall\n",
        "!pip install torch==2.3.1 topological-adam --quiet --upgrade\n",
        "\n",
        "# 2ï¸âƒ£  Import AFTER install (avoid double TORCH_LIBRARY registration)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np, math, random\n",
        "from collections import defaultdict\n",
        "from topological_adam import TopologicalAdam\n",
        "from matplotlib import pyplot as plt\n",
        "from numba import njit\n",
        "\n",
        "# ===============================================================\n",
        "# 1. RDT MATH\n",
        "# ===============================================================\n",
        "def rdt_depth(n, alpha=1.5):\n",
        "    if n < 2: return 0\n",
        "    x, depth = n, 0\n",
        "    while x > 1 and depth < 1000:\n",
        "        d = max(2, int(math.log(x) ** alpha))\n",
        "        if x < d: break\n",
        "        x //= d\n",
        "        depth += 1\n",
        "    return depth\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def rdt_grid_size(n, alpha=1.5):\n",
        "    if n <= 1:\n",
        "        return 2\n",
        "    d = max(2, int(np.log(n + 1) ** alpha))\n",
        "    return min(d, 32)\n",
        "\n",
        "# ===============================================================\n",
        "# 2. RDT SPATIAL INDEX\n",
        "# ===============================================================\n",
        "class RDTEmbeddingIndex:\n",
        "    def __init__(self, vocab_size, embedding_dim, alpha=1.5):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.alpha = alpha\n",
        "        self.shells = defaultdict(list)\n",
        "        self.word_depth = {}\n",
        "        for idx in range(vocab_size):\n",
        "            depth = rdt_depth(idx, alpha)\n",
        "            self.shells[depth].append(idx)\n",
        "            self.word_depth[idx] = depth\n",
        "        self.shell_grid_sizes = {}\n",
        "        for depth, words in self.shells.items():\n",
        "            n = len(words)\n",
        "            self.shell_grid_sizes[depth] = rdt_grid_size(n, alpha)\n",
        "        print(f\"\\nğŸ”¬ RDT Spatial Index:\")\n",
        "        for depth in sorted(self.shells.keys()):\n",
        "            n = len(self.shells[depth])\n",
        "            g = self.shell_grid_sizes[depth]\n",
        "            print(f\"   Shell {depth}: {n} words, grid {g}Ã—{g}\")\n",
        "\n",
        "    def find_nearest_in_shell(self, embedding, target_shell, embeddings_dict, k=5):\n",
        "        if target_shell not in self.shells:\n",
        "            return []\n",
        "        candidates = self.shells[target_shell]\n",
        "        distances = []\n",
        "        for word_idx in candidates:\n",
        "            emb = embeddings_dict[word_idx]\n",
        "            sim = F.cosine_similarity(embedding.unsqueeze(0), emb.unsqueeze(0))\n",
        "            distances.append((word_idx, sim.item()))\n",
        "        distances.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [idx for idx, _ in distances[:k]]\n",
        "\n",
        "    def hierarchical_search(self, embedding, current_word_idx, embeddings_dict, k=10):\n",
        "        current_shell = self.word_depth.get(current_word_idx, 0)\n",
        "        candidates = self.find_nearest_in_shell(embedding, current_shell, embeddings_dict, k=k)\n",
        "        if len(candidates) < k:\n",
        "            for offset in [1, -1, 2, -2]:\n",
        "                nearby_shell = current_shell + offset\n",
        "                if nearby_shell in self.shells:\n",
        "                    more = self.find_nearest_in_shell(embedding, nearby_shell, embeddings_dict, k=k-len(candidates))\n",
        "                    candidates.extend(more)\n",
        "                    if len(candidates) >= k:\n",
        "                        break\n",
        "        return candidates[:k]\n",
        "\n",
        "# ===============================================================\n",
        "# 3. CORPUS\n",
        "# ===============================================================\n",
        "def generate_rich_corpus():\n",
        "    subjects = [\n",
        "        'the man', 'the woman', 'the child', 'the king', 'the queen',\n",
        "        'the soldier', 'the merchant', 'the teacher', 'the old man',\n",
        "        'the young woman', 'a stranger', 'the traveler', 'the farmer',\n",
        "        'the priest', 'the warrior', 'the beggar', 'the noble'\n",
        "    ]\n",
        "    verbs = [\n",
        "        'walked','ran','went','came','spoke','thought','found','discovered',\n",
        "        'remembered','believed','understood','left','arrived','departed',\n",
        "        'searched','wondered','feared','hoped','carried','held','took','gave','brought','sent'\n",
        "    ]\n",
        "    locations = [\n",
        "        'to the house','to the market','to the river','to the forest',\n",
        "        'to the castle','through the valley','across the land','to the mountain',\n",
        "        'to the sea','to the village','to the city','through the door',\n",
        "        'into the darkness','toward the light','beyond the horizon','near the gate'\n",
        "    ]\n",
        "    adjectives = [\n",
        "        'happy','sad','brave','wise','afraid','calm','strong','gentle','proud','humble',\n",
        "        'kind','cruel','young','old','rich','poor','noble','simple','great','small'\n",
        "    ]\n",
        "    times = [\n",
        "        'in the morning','at night','at dawn','at dusk','yesterday','long ago',\n",
        "        'one day','when winter came','when spring arrived','at midnight',\n",
        "        'before sunrise','after sunset'\n",
        "    ]\n",
        "    objects = [\n",
        "        'a sword','a book','a letter','a key','a treasure','a secret','a truth',\n",
        "        'a dream','a memory','a promise','a gift'\n",
        "    ]\n",
        "    corpus=[]\n",
        "    for _ in range(4000):\n",
        "        corpus.append(f\"{random.choice(subjects)} {random.choice(verbs)} {random.choice(locations)}\".split())\n",
        "    for _ in range(3000):\n",
        "        corpus.append(f\"{random.choice(subjects)} was {random.choice(adjectives)}\".split())\n",
        "    for _ in range(3000):\n",
        "        corpus.append(f\"{random.choice(times)} {random.choice(subjects)} {random.choice(verbs)}\".split())\n",
        "    for _ in range(2000):\n",
        "        corpus.append(f\"{random.choice(subjects)} {random.choice(['found','held','carried','brought','took'])} {random.choice(objects)}\".split())\n",
        "    for _ in range(2000):\n",
        "        s1, adj1 = random.choice(subjects), random.choice(adjectives)\n",
        "        s2, adj2 = random.choice(['he','she','they']), random.choice(adjectives)\n",
        "        corpus.append(f\"{s1} was {adj1} and {s2} was {adj2}\".split())\n",
        "    for _ in range(2000):\n",
        "        corpus.append(f\"{random.choice(['the','a'])} {random.choice(adjectives)} {random.choice(['man','woman','child','king','soldier'])} {random.choice(verbs)}\".split())\n",
        "    random.shuffle(corpus)\n",
        "    vocab = sorted(set(word for sent in corpus for word in sent))\n",
        "    print(f\"ğŸ“š Corpus: {len(corpus):,} sentences, {len(vocab)} words\")\n",
        "    return corpus, vocab\n",
        "\n",
        "corpus,vocab = generate_rich_corpus()\n",
        "\n",
        "# ===============================================================\n",
        "# 4. TOPOLOGICAL NEURAL NETWORK\n",
        "# ===============================================================\n",
        "class TopologicalNeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=256, hidden_dim=512, output_dim=256, lambda_topo=1.0):\n",
        "        super().__init__()\n",
        "        self.lambda_topo=lambda_topo\n",
        "        self.fc1=nn.Linear(input_dim,hidden_dim)\n",
        "        self.fc2=nn.Linear(hidden_dim,hidden_dim)\n",
        "        self.fc3=nn.Linear(hidden_dim,output_dim)\n",
        "        self.layer_norm=nn.LayerNorm(hidden_dim)\n",
        "        self.energy=self.coupling=self.stability=self.energy_ratio=0.0\n",
        "\n",
        "    def compute_topological_terms(self,activations):\n",
        "        eps=1e-8\n",
        "        E=torch.mean(activations**2)\n",
        "        grad=torch.autograd.grad(E,activations,retain_graph=True,create_graph=True,allow_unused=True)\n",
        "        if grad[0] is None:\n",
        "            C=E\n",
        "        else:\n",
        "            C_raw=torch.mean(grad[0]**2)\n",
        "            N=activations.numel()\n",
        "            scale=4.0/(N**2)\n",
        "            C=C_raw/(scale+eps)\n",
        "        ratio=E/(C+eps)\n",
        "        ratio_clamped=torch.clamp(ratio,0.25,4.0)\n",
        "        E_d,C_d,S_d=E.detach(),C.detach(),torch.abs(ratio-1.0).detach()\n",
        "        return E_d,C_d,S_d,ratio_clamped\n",
        "\n",
        "    def forward(self,x):\n",
        "        reshaped=False\n",
        "        if len(x.shape)==3:\n",
        "            b,s,d=x.shape\n",
        "            x=x.reshape(b*s,d)\n",
        "            reshaped=True\n",
        "        h1=F.relu(self.fc1(x))\n",
        "        h2=F.relu(self.fc2(h1))\n",
        "        h2n=self.layer_norm(h2)\n",
        "        out=self.fc3(h2n)\n",
        "        if self.training:\n",
        "            E_d,C_d,S_d,ratio_ctrl=self.compute_topological_terms(h2n)\n",
        "            self.energy,self.coupling,self.stability=E_d.item(),C_d.item(),S_d.item()\n",
        "            if not hasattr(self,\"_ratio_ema\"): self._ratio_ema=ratio_ctrl.detach()\n",
        "            self._ratio_ema=0.9*self._ratio_ema+0.1*ratio_ctrl.detach()\n",
        "            correction=self.lambda_topo*torch.log(self._ratio_ema+1e-8)\n",
        "            out=out+correction*torch.tanh(out)\n",
        "            self.energy_ratio=float((E_d/(C_d+1e-8)).cpu())\n",
        "        if reshaped: out=out.reshape(b,s,-1)\n",
        "        return out\n",
        "\n",
        "# ===============================================================\n",
        "# 5. COMPLETE MODEL\n",
        "# ===============================================================\n",
        "class RDTLanguageModel(nn.Module):\n",
        "    def __init__(self,vocab,emb_dim=256,hidden_dim=512,alpha=1.5):\n",
        "        super().__init__()\n",
        "        self.alpha=alpha\n",
        "        self.word2idx={w:i for i,w in enumerate(vocab)}\n",
        "        self.idx2word={i:w for w,i in self.word2idx.items()}\n",
        "        self.vocab_size=len(vocab)\n",
        "        self.rdt_index=RDTEmbeddingIndex(self.vocab_size,emb_dim,alpha)\n",
        "        self.embed=nn.Embedding(self.vocab_size,emb_dim)\n",
        "        self.tnn=TopologicalNeuralNetwork(input_dim=emb_dim,hidden_dim=hidden_dim,output_dim=emb_dim)\n",
        "        self.fc_out=nn.Linear(emb_dim,self.vocab_size)\n",
        "        print(f\"\\nğŸ“Š Complete Model:\\n   Parameters: {sum(p.numel() for p in self.parameters()):,}\\n   Components: RDT Index + TNN (MHD) + Spatial Search\")\n",
        "\n",
        "    def forward(self,x):\n",
        "        e=self.embed(x)\n",
        "        h=self.tnn(e)\n",
        "        out=self.fc_out(h)\n",
        "        return out,h\n",
        "\n",
        "    def compute_rdt_spatial_loss(self,predictions,targets,hidden_states):\n",
        "        b,s,v=predictions.shape\n",
        "        preds=torch.argmax(predictions,dim=-1).view(-1)\n",
        "        targs=targets.view(-1)\n",
        "        with torch.no_grad():\n",
        "            emb_dict={i:self.embed.weight[i] for i in range(self.vocab_size)}\n",
        "        total,n=0.0,0\n",
        "        for i in random.sample(range(len(preds)),min(100,len(preds))):\n",
        "            p,t=preds[i].item(),targs[i].item()\n",
        "            if t==0: continue\n",
        "            h=hidden_states.view(-1,hidden_states.size(-1))[i]\n",
        "            pd,td=self.rdt_index.word_depth[p],self.rdt_index.word_depth[t]\n",
        "            depth_bonus=1.0 if pd==td else (min(pd,td)+1)/(max(pd,td)+1)\n",
        "            cands=self.rdt_index.hierarchical_search(h,t,emb_dict,k=10)\n",
        "            if p in cands:\n",
        "                r=cands.index(p)\n",
        "                total+=depth_bonus/(r+1)\n",
        "            else: total+=depth_bonus*0.1\n",
        "            n+=1\n",
        "        return total/n if n>0 else 0.0\n",
        "\n",
        "# ===============================================================\n",
        "# 6. TRAINING\n",
        "# ===============================================================\n",
        "def prepare_batch(sents,word2idx,maxlen=15):\n",
        "    bx,by=[],[]\n",
        "    for s in sents:\n",
        "        if len(s)<2: continue\n",
        "        idxs=[word2idx.get(w,0) for w in s]\n",
        "        x,y=idxs[:-1],idxs[1:]\n",
        "        if len(x)<maxlen:\n",
        "            x=x+[0]*(maxlen-len(x));y=y+[0]*(maxlen-len(y))\n",
        "        else: x,y=x[:maxlen],y[:maxlen]\n",
        "        bx.append(x);by.append(y)\n",
        "    if not bx: return None,None\n",
        "    return torch.tensor(bx,device=device),torch.tensor(by,device=device)\n",
        "\n",
        "def train_model(model,corpus,epochs=50,initial_lr=1e-3,batch_size=64):\n",
        "    opt=TopologicalAdam(model.parameters(),lr=initial_lr)\n",
        "    crit=nn.CrossEntropyLoss()\n",
        "    sch=torch.optim.lr_scheduler.ReduceLROnPlateau(opt,mode='min',factor=0.5,patience=5)\n",
        "    L,S,E,C,R,AE=[],[],[],[],[],[]\n",
        "    best=float('inf')\n",
        "    print(\"\\nğŸ”¥ Training COMPLETE SYSTEM WITH MHD INSIGHTS:\")\n",
        "    for ep in range(1,epochs+1):\n",
        "        random.shuffle(corpus)\n",
        "        el,es,ee,ec,er,nb=0,0,0,0,0,0\n",
        "        for i in range(0,len(corpus),batch_size):\n",
        "            b=corpus[i:i+batch_size]\n",
        "            x,y=prepare_batch(b,model.word2idx)\n",
        "            if x is None: continue\n",
        "            o,h=model(x)\n",
        "            loss=crit(o.view(-1,model.vocab_size),y.view(-1))\n",
        "            sb=model.compute_rdt_spatial_loss(o,y,h)\n",
        "            tl=loss-0.5*sb\n",
        "            opt.zero_grad();tl.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "            opt.step()\n",
        "            el+=loss.item();es+=sb;ee+=model.tnn.energy;ec+=model.tnn.coupling;er+=model.tnn.energy_ratio;nb+=1\n",
        "        if nb:\n",
        "            ml,ms,me,mc,mr,ma=el/nb,es/nb,ee/nb,ec/nb,er/nb,opt.energy()\n",
        "            L.append(ml);S.append(ms);E.append(me);C.append(mc);R.append(mr);AE.append(ma)\n",
        "            sch.step(ml)\n",
        "            imp=ml<best\n",
        "            if imp: best=ml\n",
        "            if ep%5==0 or ep==1:\n",
        "                print(f\"Epoch {ep:2d}: loss={ml:.4f} | spatial={ms:.4f} | E/C_ratio={mr:.3f} | TNN_E={me:.2e} | Adam_E={ma:.2e} {'ğŸ”¥' if imp else ''}\")\n",
        "    print(f\"\\nâœ… Done! Best loss {best:.4f}\")\n",
        "    return L,S,E,C,R,AE\n",
        "\n",
        "# ===============================================================\n",
        "# 7. GENERATION\n",
        "# ===============================================================\n",
        "def generate_text(model,start_text,max_len=15,temperature=0.8):\n",
        "    model.eval();w=start_text.lower().split()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_len):\n",
        "            x=torch.tensor([[model.word2idx.get(t,0) for t in w]],device=device)\n",
        "            o,_=model(x)\n",
        "            logit=o[0,-1,:]/temperature\n",
        "            probs=F.softmax(logit,dim=0)\n",
        "            n=torch.multinomial(probs,1).item()\n",
        "            if n==0: break\n",
        "            w.append(model.idx2word[n])\n",
        "            if len(w)>20: break\n",
        "    return ' '.join(w)\n",
        "\n",
        "# ===============================================================\n",
        "# 8. RUN SYSTEM\n",
        "# ===============================================================\n",
        "print(\"=\"*70)\n",
        "print(\"COMPLETE SYSTEM: RDT + TNN (MHD) + TOPOLOGICAL ADAM + SPATIAL INDEX\")\n",
        "print(\"=\"*70)\n",
        "torch.manual_seed(42)\n",
        "model=RDTLanguageModel(vocab,emb_dim=256,hidden_dim=512,alpha=1.5).to(device)\n",
        "L,S,E,C,R,AE=train_model(model,corpus,epochs=50,initial_lr=1e-3,batch_size=64)\n",
        "\n",
        "print(\"\\n\"+\"=\"*70)\n",
        "print(\"TEXT GENERATION\")\n",
        "print(\"=\"*70)\n",
        "for p in [\"the man\",\"in the morning\",\"she was\",\"long ago\"]:\n",
        "    print(f\"\\n'{p}':\")\n",
        "    for i in range(3):\n",
        "        print(f\"  {generate_text(model,p,max_len=12)}\")\n",
        "\n",
        "# ===============================================================\n",
        "# 9. VISUALIZATION\n",
        "# ===============================================================\n",
        "fig,ax=plt.subplots(2,3,figsize=(18,10))\n",
        "ax[0,0].plot(L,'b-',lw=2);ax[0,0].axhline(y=0.5,color='r',ls='--',alpha=0.5);ax[0,0].set_title(\"Loss\");ax[0,0].grid(True)\n",
        "ax[0,1].plot(S,'g-',lw=2);ax[0,1].set_title(\"RDT Spatial Bonus\");ax[0,1].grid(True)\n",
        "ax[0,2].plot(R,'orange',lw=2);ax[0,2].axhline(y=1.0,color='r',ls='--',alpha=0.5);ax[0,2].set_title(\"E/C Ratio\");ax[0,2].grid(True)\n",
        "ax[1,0].plot(E,'r-',lw=2,label='Energy');ax[1,0].plot(C,'purple',lw=2,label='Coupling');ax[1,0].legend();ax[1,0].set_title(\"TNN Energy & Coupling\");ax[1,0].grid(True)\n",
        "ax[1,1].plot(AE,'darkblue',lw=2);ax[1,1].set_title(\"Topological Adam Energy\");ax[1,1].grid(True)\n",
        "ax[1,2].plot(L,'b-',lw=2,alpha=0.7,label='Loss');ax[1,2].plot([s*2 for s in S],'g-',lw=2,alpha=0.7,label='SpatialÃ—2');ax[1,2].legend();ax[1,2].set_title(\"Loss vs Spatial\");ax[1,2].grid(True)\n",
        "plt.tight_layout();plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL METRICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Loss: {L[-1]:.4f}\")\n",
        "print(f\"Spatial bonus: {S[-1]:.4f}\")\n",
        "print(f\"E/C ratio: {R[-1]:.3f} (ideal=1.0)\")\n",
        "print(f\"TNN energy: {E[-1]:.2e}\")\n",
        "print(f\"TNN coupling: {C[-1]:.2e}\")\n",
        "print(f\"Topological Adam energy: {AE[-1]:.2e}\")\n",
        "print(\"=\"*70)\n",
        "print(\"âœ… ALL COMPONENTS ACTIVE & STABLE (MHD normalized)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f5nRyzDy1uXs",
        "outputId": "d4d543ab-0448-4a64-dd90-e0d031893761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.3.1 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mğŸ“š Corpus: 16,000 sentences, 118 words\n",
            "======================================================================\n",
            "COMPLETE SYSTEM: RDT + TNN (MHD) + TOPOLOGICAL ADAM + SPATIAL INDEX\n",
            "======================================================================\n",
            "\n",
            "ğŸ”¬ RDT Spatial Index:\n",
            "   Shell 0: 2 words, grid 2Ã—2\n",
            "   Shell 1: 2 words, grid 2Ã—2\n",
            "   Shell 2: 11 words, grid 3Ã—3\n",
            "   Shell 3: 90 words, grid 9Ã—9\n",
            "   Shell 4: 13 words, grid 4Ã—4\n",
            "\n",
            "ğŸ“Š Complete Model:\n",
            "   Parameters: 587,126\n",
            "   Components: RDT Index + TNN (MHD) + Spatial Search\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "type object 'GuardSource' has no attribute 'LOCAL_NN_MODULE'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1332465012.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRDTLanguageModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1332465012.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, corpus, epochs, initial_lr, batch_size)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTopologicalAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0mcrit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0msch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/topological_adam/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, eta, mu0, w_topo, field_init_scale, target_energy)\u001b[0m\n\u001b[1;32m     13\u001b[0m                         \u001b[0mfield_init_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield_init_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                         target_energy=target_energy)\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_J_accum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallback_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_compile_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcode_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcode_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/convert_frame.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_traceback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mformat_traceback_short\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompilerFn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbytecode_analysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mremove_dead_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_pointless_jumps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/trace_rules.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNP_SUPPORTED_MODULES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_if_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m from .variables import (\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mFunctorchHigherOrderVariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mypy: ignore-errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariableTracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuiltin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBuiltinVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnumVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_scope_id\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcurrent_scope_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munimplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAttrSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mistype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_dynamo/source.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# so those cases are omitted intentionally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m _GUARD_SOURCE_NN_MODULE = {\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_NN_MODULE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_NN_MODULE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_NN_MODULE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGuardSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCAL_NN_MODULE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'GuardSource' has no attribute 'LOCAL_NN_MODULE'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================================================\n",
        "#  CLEAN TORCH + TOPOLOGICAL ADAM INSTALL (COMPATIBLE VERSIONS)\n",
        "# ===============================================================\n",
        "\n",
        "!pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --quiet --extra-index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install topological-adam --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np, math, random\n",
        "from collections import defaultdict\n",
        "from topological_adam import TopologicalAdam\n",
        "from matplotlib import pyplot as plt\n",
        "from numba import njit\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"ğŸš€ Device: {device}\")\n",
        "print(f\"âœ… Torch version: {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeBhsxAH4L1Q",
        "outputId": "1a59a6b5-b289-47cc-d187-b2356d1479e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Device: cpu\n",
            "âœ… Torch version: 2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ğŸ”® Topological State Manager v1 â€” RDT + TNN Integrated Memory\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import defaultdict\n",
        "\n",
        "class TopologicalStateManager(nn.Module):\n",
        "    \"\"\"\n",
        "    Field-based persistent memory for the Topological-Geometric LM.\n",
        "    Stores and retrieves energy configurations (Î¦) across sessions.\n",
        "    Integrates directly with the TNN and RDT geometry.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, decay=0.995, coupling=0.75, device=None):\n",
        "        super().__init__()\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.dim = dim\n",
        "        self.decay = decay        # energy decay factor per update\n",
        "        self.coupling = coupling  # field coupling coefficient Îº\n",
        "        self.memory = defaultdict(lambda: torch.zeros(dim, device=self.device))\n",
        "        self.energy_map = defaultdict(float)\n",
        "        self.step = 0\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Encode: store current field into memory\n",
        "    # --------------------------------------------\n",
        "    def encode(self, shell_id, field_vec, energy):\n",
        "        if field_vec is None: return\n",
        "        if shell_id not in self.memory:\n",
        "            self.memory[shell_id] = field_vec.detach().clone()\n",
        "            self.energy_map[shell_id] = energy\n",
        "        else:\n",
        "            old = self.memory[shell_id]\n",
        "            # weighted merge by energy + coupling\n",
        "            merged = (\n",
        "                self.coupling * field_vec +\n",
        "                (1 - self.coupling) * old * self.decay\n",
        "            )\n",
        "            self.memory[shell_id] = merged.detach().clone()\n",
        "            self.energy_map[shell_id] = (\n",
        "                self.coupling * energy + (1 - self.coupling) * self.energy_map[shell_id]\n",
        "            )\n",
        "        self.step += 1\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Recall: retrieve a field state near a shell\n",
        "    # --------------------------------------------\n",
        "    def recall(self, shell_id, radius=1):\n",
        "        # get nearest memory shell by geometric distance\n",
        "        keys = list(self.memory.keys())\n",
        "        if not keys:\n",
        "            return torch.zeros(self.dim, device=self.device), 0.0\n",
        "        diffs = [abs(k - shell_id) for k in keys]\n",
        "        nearest = keys[int(torch.argmin(torch.tensor(diffs)))]\n",
        "        return self.memory[nearest], self.energy_map[nearest]\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Global Decay: periodic relaxation to equilibrium\n",
        "    # --------------------------------------------\n",
        "    def relax(self):\n",
        "        for k in list(self.memory.keys()):\n",
        "            self.memory[k] *= self.decay\n",
        "            self.energy_map[k] *= self.decay\n",
        "\n",
        "    # --------------------------------------------\n",
        "    # Entropy Estimate (diagnostic)\n",
        "    # --------------------------------------------\n",
        "    def entropy(self):\n",
        "        vals = torch.stack(list(self.memory.values())) if self.memory else torch.zeros(1, self.dim, device=self.device)\n",
        "        return torch.mean(torch.var(vals, dim=0)).item()\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¬ Integration Hook for your LM\n",
        "# ============================================================\n",
        "\n",
        "def integrate_state_manager(model, dim):\n",
        "    \"\"\"\n",
        "    Attaches the TSM to an existing model instance.\n",
        "    \"\"\"\n",
        "    model.state_manager = TopologicalStateManager(dim=dim, device=next(model.parameters()).device)\n",
        "\n",
        "    def after_forward_hook(module, input, output):\n",
        "        # automatically store field after each batch\n",
        "        if hasattr(module, 'depth'):\n",
        "            energy = getattr(module, 'field_energy', 1.0)\n",
        "            model.state_manager.encode(shell_id=module.depth, field_vec=output.mean(0), energy=energy)\n",
        "\n",
        "    # hook into your TNN forward output\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.register_forward_hook(after_forward_hook)\n",
        "\n",
        "    print(\"âœ… Topological State Manager integrated with model.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# âœ… Example Integration (Run Once)\n",
        "# ============================================================\n",
        "\n",
        "# assuming your model variable is `model`\n",
        "model = integrate_state_manager(model, dim=256)\n",
        "\n",
        "# Example usage:\n",
        "# During training, states auto-encode via hooks.\n",
        "# You can manually recall and inject context like this:\n",
        "\n",
        "shell = 3\n",
        "field_vec, energy = model.state_manager.recall(shell)\n",
        "print(f\"ğŸ” Recalled shell {shell} | Energy={energy:.4f} | Entropyâ‰ˆ{model.state_manager.entropy():.6f}\")"
      ],
      "metadata": {
        "id": "MmTNBGKCtCzz",
        "outputId": "207c83f6-496a-473f-b5db-338d0f0ccb2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2814985535.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# assuming your model variable is `model`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrate_state_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}